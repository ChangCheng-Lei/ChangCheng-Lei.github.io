<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ChangCheng</title>
  
  <subtitle>ChangCheng Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-21T09:12:39.066Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>[object Object]</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Lucene JAVA 教程</title>
    <link href="http://yoursite.com/2019/07/21/lucene-java-api/"/>
    <id>http://yoursite.com/2019/07/21/lucene-java-api/</id>
    <published>2019-07-21T08:49:43.000Z</published>
    <updated>2019-07-21T09:12:39.066Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#lucene-jiao-cheng-index-and-search">Lucene 教程 - Index and Search</a><ul><li><a href="#tian-jia-maven-yi-lai">添加Maven 依赖</a></li><li><a href="#chuang-jian-lucene-index">创建Lucene Index</a><ul><li><a href="#chuang-jian-indexwriter">创建IndexWriter</a></li><li><a href="#chuang-jian-document">创建Document</a></li><li><a href="#jiang-document-xie-ru-dao-suo-yin-zhong">将Document写入到索引中</a></li></ul></li><li><a href="#lucene-cha-xun">Lucene 查询</a><ul><li><a href="#chuang-jian-indexsearcher">创建IndexSearcher</a></li><li><a href="#cha-xun-lucene-docs">查询Lucene docs</a></li><li><a href="#cha-xun-wan-zheng-dai-ma">查询完整代码</a></li></ul></li></ul></li></ul><!-- tocstop --></div><h1><span id="lucene-jiao-cheng-index-and-search">Lucene 教程 - Index and Search</span><a href="#lucene-jiao-cheng-index-and-search" class="header-anchor"></a></h1><p>本文档主要内容为如何包含通过JAVA API 传概念Lucene 的Index， 实现Lucene 的查询功能。</p><h2><span id="tian-jia-maven-yi-lai">添加Maven 依赖</span><a href="#tian-jia-maven-yi-lai" class="header-anchor"></a></h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">lucene.version</span>&gt;</span>8.1.1<span class="tag">&lt;/<span class="name">lucene.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.lucene<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lucene-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;lucene.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.lucene<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lucene-analyzers-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;lucene.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.lucene<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lucene-queryparser<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;lucene.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2><span id="chuang-jian-lucene-index">创建Lucene Index</span><a href="#chuang-jian-lucene-index" class="header-anchor"></a></h2><h3><span id="chuang-jian-indexwriter">创建IndexWriter</span><a href="#chuang-jian-indexwriter" class="header-anchor"></a></h3><p><em>org.apache.lucene.index.IndexWriter</em> 提供创建和管理Index的功能，其构造函数主要包含<em>FSDirectory</em> 和<em>IndexWriterConfig</em>两个参数，详细<a href="http://lucene.apache.org/core/8_1_1/core/index.html" target="_blank" rel="noopener">API</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> IndexWriter <span class="title">createWriter</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">    FSDirectory directory = FSDirectory.open(Paths.get(PATH_INDEX_DIR));</span><br><span class="line">    IndexWriterConfig config = <span class="keyword">new</span> IndexWriterConfig(<span class="keyword">new</span> StandardAnalyzer());</span><br><span class="line">    IndexWriter writer = <span class="keyword">new</span> IndexWriter(directory,config);</span><br><span class="line">    <span class="keyword">return</span> writer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="chuang-jian-document">创建Document</span><a href="#chuang-jian-document" class="header-anchor"></a></h3><p><em>org.apache.lucene.document.Document</em>代表我们想要创建的索引</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Document <span class="title">createDocument</span><span class="params">(Integer id, String firstName, String lastName, String website)</span></span>&#123;</span><br><span class="line">        Document document = <span class="keyword">new</span> Document();</span><br><span class="line">        document.add(<span class="keyword">new</span> StringField(<span class="string">"id"</span>,id.toString(), Field.Store.YES));</span><br><span class="line">        document.add(<span class="keyword">new</span> TextField(<span class="string">"firstName"</span>, firstName , Field.Store.YES));</span><br><span class="line">        document.add(<span class="keyword">new</span> TextField(<span class="string">"lastName"</span>, lastName , Field.Store.YES));</span><br><span class="line">        document.add(<span class="keyword">new</span> TextField(<span class="string">"website"</span>, website , Field.Store.YES));</span><br><span class="line">        <span class="keyword">return</span> document;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3><span id="jiang-document-xie-ru-dao-suo-yin-zhong">将Document写入到索引中</span><a href="#jiang-document-xie-ru-dao-suo-yin-zhong" class="header-anchor"></a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.lucene;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.analysis.standard.StandardAnalyzer;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.document.Document;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.document.Field;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.document.StringField;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.document.TextField;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.index.IndexWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.index.IndexWriterConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.store.FSDirectory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.file.Paths;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LuceneWriteIndexExample</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH_INDEX_DIR = <span class="string">"D:\\Learn\\Intellij\\elastic-search-learn\\lucene-learn\\index_dir"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        IndexWriter writer = createWriter();</span><br><span class="line">        List&lt;Document&gt; documents = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        Document document1 = createDocument(<span class="number">1</span>, <span class="string">"LCC"</span>, <span class="string">"XXX"</span>, <span class="string">"howtodoinjava.com"</span>);</span><br><span class="line">        Document document2 = createDocument(<span class="number">2</span>, <span class="string">"firstName"</span>, <span class="string">"LastName"</span>, <span class="string">"www.baidu.com"</span>);</span><br><span class="line">        documents.add(document1);</span><br><span class="line">        documents.add(document2);</span><br><span class="line">        <span class="comment">//delete all for first</span></span><br><span class="line">        writer.deleteAll();</span><br><span class="line">        writer.addDocuments(documents);</span><br><span class="line">        writer.commit();</span><br><span class="line">        writer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> IndexWriter <span class="title">createWriter</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        FSDirectory directory = FSDirectory.open(Paths.get(PATH_INDEX_DIR));</span><br><span class="line">        IndexWriterConfig config = <span class="keyword">new</span> IndexWriterConfig(<span class="keyword">new</span> StandardAnalyzer());</span><br><span class="line">        IndexWriter writer = <span class="keyword">new</span> IndexWriter(directory, config);</span><br><span class="line">        <span class="keyword">return</span> writer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Document <span class="title">createDocument</span><span class="params">(Integer id, String firstName, String lastName, String website)</span> </span>&#123;</span><br><span class="line">        Document document = <span class="keyword">new</span> Document();</span><br><span class="line">        document.add(<span class="keyword">new</span> StringField(<span class="string">"id"</span>, id.toString(), Field.Store.YES));</span><br><span class="line">        document.add(<span class="keyword">new</span> TextField(<span class="string">"firstName"</span>, firstName, Field.Store.YES));</span><br><span class="line">        document.add(<span class="keyword">new</span> TextField(<span class="string">"lastName"</span>, lastName, Field.Store.YES));</span><br><span class="line">        document.add(<span class="keyword">new</span> TextField(<span class="string">"website"</span>, website, Field.Store.YES));</span><br><span class="line">        <span class="keyword">return</span> document;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我们执行程序过后，会发现lucene index 已经写入到我们配置的文件夹当中了<br><img src="/2019/07/21/lucene-java-api/1563698487271.png" alt="Alt text"></p><h2><span id="lucene-cha-xun">Lucene 查询</span><a href="#lucene-cha-xun" class="header-anchor"></a></h2><h3><span id="chuang-jian-indexsearcher">创建IndexSearcher</span><a href="#chuang-jian-indexsearcher" class="header-anchor"></a></h3><p><em>org.apache.lucene.search.IndexSearcher</em>用来从Index中查询document,初始化时候需要指定正确的Index文件夹</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> IndexSearcher <span class="title">createSearcher</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Directory directory = FSDirectory.open(Paths.get(PATH_INDEX_DIR));</span><br><span class="line">        IndexReader reader = DirectoryReader.open(directory);</span><br><span class="line">        IndexSearcher searcher = <span class="keyword">new</span> IndexSearcher(reader);</span><br><span class="line">        <span class="keyword">return</span> searcher;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3><span id="cha-xun-lucene-docs">查询Lucene docs</span><a href="#cha-xun-lucene-docs" class="header-anchor"></a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">IndexSearcher searcher = createSearcher();</span><br><span class="line">        <span class="comment">//Search by ID</span></span><br><span class="line">        TopDocs foundDocs = searchById(<span class="number">1</span>,searcher);</span><br><span class="line">        System.out.println(<span class="string">"Total hits : "</span> + foundDocs.totalHits);</span><br><span class="line">        <span class="keyword">for</span> (ScoreDoc sd : foundDocs.scoreDocs)</span><br><span class="line">        &#123;</span><br><span class="line">            System.out.println(sd);</span><br><span class="line">            Document doc = searcher.doc(sd.doc);</span><br><span class="line">            System.out.println(String.format(doc.get(<span class="string">"firstName"</span>)));</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3><span id="cha-xun-wan-zheng-dai-ma">查询完整代码</span><a href="#cha-xun-wan-zheng-dai-ma" class="header-anchor"></a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.lucene;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.analysis.standard.StandardAnalyzer;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.document.Document;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.index.DirectoryReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.index.IndexReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.queryparser.classic.ParseException;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.queryparser.classic.QueryParser;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.search.IndexSearcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.search.Query;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.search.ScoreDoc;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.search.TopDocs;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.store.Directory;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.store.FSDirectory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.nio.file.Paths;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LuceneSearchDocumentExample</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH_INDEX_DIR = <span class="string">"D:\\Learn\\Intellij\\elastic-search-learn\\lucene-learn\\index_dir"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        IndexSearcher searcher = createSearcher();</span><br><span class="line">        <span class="comment">//Search by ID</span></span><br><span class="line">        TopDocs foundDocs = searchById(<span class="number">1</span>, searcher);</span><br><span class="line">        System.out.println(<span class="string">"Total hits : "</span> + foundDocs.totalHits);</span><br><span class="line">        <span class="keyword">for</span> (ScoreDoc sd : foundDocs.scoreDocs) &#123;</span><br><span class="line">            System.out.println(sd);</span><br><span class="line">            Document doc = searcher.doc(sd.doc);</span><br><span class="line">            System.out.println(String.format(doc.get(<span class="string">"firstName"</span>)));</span><br><span class="line">        &#125;       </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> TopDocs <span class="title">searchById</span><span class="params">(Integer id, IndexSearcher searcher)</span> <span class="keyword">throws</span> ParseException, IOException </span>&#123;</span><br><span class="line">        QueryParser queryParser = <span class="keyword">new</span> QueryParser(<span class="string">"id"</span>, <span class="keyword">new</span> StandardAnalyzer());</span><br><span class="line">        Query query = queryParser.parse(id.toString());</span><br><span class="line">        TopDocs topDocs = searcher.search(query, <span class="number">10</span>);</span><br><span class="line">        <span class="keyword">return</span> topDocs;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> IndexSearcher <span class="title">createSearcher</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Directory directory = FSDirectory.open(Paths.get(PATH_INDEX_DIR));</span><br><span class="line">        IndexReader reader = DirectoryReader.open(directory);</span><br><span class="line">        IndexSearcher searcher = <span class="keyword">new</span> IndexSearcher(reader);</span><br><span class="line">        <span class="keyword">return</span> searcher;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行程序即可返回正确的数据.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#lucene-jiao-cheng-index-and-search&quot;&gt;Lucene 教程 - Index and Search&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#t
      
    
    </summary>
    
    
      <category term="Lucene" scheme="http://yoursite.com/tags/Lucene/"/>
    
      <category term="Elasticsearch" scheme="http://yoursite.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Lucene 基础教程</title>
    <link href="http://yoursite.com/2019/07/21/lucene-basic/"/>
    <id>http://yoursite.com/2019/07/21/lucene-basic/</id>
    <published>2019-07-21T08:48:58.000Z</published>
    <updated>2019-07-21T09:12:39.065Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#lucene-ji-chu-jiao-cheng">Lucene 基础教程</a><ul><li><a href="#luncene-ji-ben-jie-shao">Luncene 基本介绍</a><ul><li><a href="#lucene-jie-jue-wen-ti">Lucene 解决问题</a></li></ul></li><li><a href="#lucene-ji-ben-shi-yong-jiao-cheng">Lucene 基本使用教程</a><ul><li><a href="#lucene-du-xie-liu-cheng">Lucene 读写流程</a></li><li><a href="#he-xin-zhu-yu">核心术语</a></li><li><a href="#jian-suo-fang-shi">检索方式</a><ul><li><a href="#dan-ge-ci-cha-xun">单个词查询</a></li><li><a href="#and">AND</a></li><li><a href="#or">OR</a></li><li><a href="#not">NOT</a></li></ul></li></ul></li></ul></li></ul><!-- tocstop --></div><h1><span id="lucene-ji-chu-jiao-cheng">Lucene 基础教程</span><a href="#lucene-ji-chu-jiao-cheng" class="header-anchor"></a></h1><h2><span id="luncene-ji-ben-jie-shao">Luncene 基本介绍</span><a href="#luncene-ji-ben-jie-shao" class="header-anchor"></a></h2><blockquote><p>Lucene 是一个基于java的全文本检索搜索引擎<br>Lucene 并不是一个完整的应用程序，而是一个代码库和API, 可以很容易的向应用程序添加搜索功能<br>Lucene <a href="http://lucene.apache.org/" target="_blank" rel="noopener">官网详细信息</a></p></blockquote><p>在Apache 基金会的Lucene项目中同时包含了一些子项目，其中关系如下</p><ul><li>Lucene Core :  就是我们常说的Lucene, 旗舰子项目，提供基于java的索引和搜索技术，以及拼写检查、高亮显示和高级分析/标记化功能。</li><li>Solr : 是基于Lucene Core 实现的高性能搜索服务，具有XML/HTTP和JSON/Python/Ruby api、hit高亮显示、分面搜索、缓存、复制和web管理界面。</li><li>PyLucene ： Python 版本的Lucene Core (原始版本是JAVA 项目)</li><li>Elasticsearch ： 基于Lucene 实现的搜索服务器，支持分布式多用户能力全文搜索引擎，基于RestFul 接口</li></ul><h3><span id="lucene-jie-jue-wen-ti">Lucene 解决问题</span><a href="#lucene-jie-jue-wen-ti" class="header-anchor"></a></h3><p>在传统数据库中，若对文本需要进行搜索需要使用like 语句</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> 表名 <span class="keyword">where</span> 字段名 <span class="keyword">like</span> ‘%关键字%’</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> article <span class="keyword">where</span> <span class="keyword">content</span> <span class="keyword">like</span> ’%here%’</span><br></pre></td></tr></table></figure><p>但是搜索会有以下问题：</p><ol><li>因为没有良好的使用数据库索引，所以效率低下</li><li>搜索效果比较差，只能对搜索关键字进行全文匹配模糊匹配，不具备分词功能，搜素结果差距较大</li></ol><p>因此Lucene 良好的解决了以上问题</p><h2><span id="lucene-ji-ben-shi-yong-jiao-cheng">Lucene 基本使用教程</span><a href="#lucene-ji-ben-shi-yong-jiao-cheng" class="header-anchor"></a></h2><h3><span id="lucene-du-xie-liu-cheng">Lucene 读写流程</span><a href="#lucene-du-xie-liu-cheng" class="header-anchor"></a></h3><p>Lucene 主要读写流程如下<br><img src="/2019/07/21/lucene-basic/1563696291565.png" alt="Alt text"></p><p>各个模块作用如下：</p><table><thead><tr><th align="left">模块</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">analysis模块</td><td align="left">主要负责词法分析以及语言处理，通过该模块可以最终形成存储或者搜索的最小单元term</td></tr><tr><td align="left">index模块</td><td align="left">主要负责索引的创建工作</td></tr><tr><td align="left">store模块</td><td align="left">主要负责索引的读写，主要目的是抽象出和平台文件系统无关的存储</td></tr><tr><td align="left">queryParser模块</td><td align="left">主要负责语法分析，把我们的查询语句生成Lucene底层可以识别的条件</td></tr><tr><td align="left">search模块</td><td align="left">主要负责对索引的搜索工作</td></tr><tr><td align="left">similarity模块</td><td align="left">主要负责相关性打分和排序的实现</td></tr><tr><td align="left">### 核心术语</td><td align="left"></td></tr><tr><td align="left">1. <strong>Term</strong> : 索引里面最小的存储和查询单元</td><td align="left"></td></tr><tr><td align="left">2. <strong>词典 Term Dictionary</strong> : 是Term的集合，词典的数据结构可以有很多种，每种都有自己的优缺点。</td><td align="left"></td></tr><tr><td align="left">3. <strong>倒排表（Posting List</strong>:  一篇文章中由多个词组成，倒排表记录的是某个词在哪些文章中出现过</td><td align="left"></td></tr><tr><td align="left">4. <strong>正向信息</strong>：原始的文档信息，可以用来做排序，聚合，展示等</td><td align="left"></td></tr><tr><td align="left">5. <strong>段（segment）</strong>:索引中最小的独立存储单元，一个索引文件由一个或者多个段组成，在Lucene中的段具有不变性，也就是说段一旦生成，在其上只能有读操作，不能有写操作</td><td align="left"></td></tr></tbody></table><h3><span id="jian-suo-fang-shi">检索方式</span><a href="#jian-suo-fang-shi" class="header-anchor"></a></h3><p>Lucene 主要支持四种检索方式</p><ul><li><strong>单个词查询</strong></li><li><strong>AND</strong></li><li><strong>OR</strong></li><li><strong>NOT</strong><h4><span id="dan-ge-ci-cha-xun">单个词查询</span><a href="#dan-ge-ci-cha-xun" class="header-anchor"></a></h4>只对一个Term进行查询，比如，若要查询字符串包含“lucene”的文档，则只需要在词典中找到Term “lucene”, 再获得倒排表中对应的文档链表即可</li></ul><h4><span id="and">AND</span><a href="#and" class="header-anchor"></a></h4><p>指对多个集合求交集，比如，若要查找即包含字符串“lucene” 又要包含“solr”的文档，则查找步骤如下</p><ol><li>在词典中找到Term ‘lucene’,得到“lucene” 对应文档的倒排表</li><li>在词典中找到Term ‘solr’,得到“solr” 对应文档的倒排表</li><li>合并链表，对两个文档链表做<strong>交集</strong>运算，合并过后结果就是即包含“lucene” 和 “sorl”</li></ol><h4><span id="or">OR</span><a href="#or" class="header-anchor"></a></h4><p>指对多个集合求并集，比如，若要查找即包含字符串“lucene” 又要包含“solr”的文档，则查找步骤如下</p><ol><li>在词典中找到Term ‘lucene’,得到“lucene” 对应文档的倒排表</li><li>在词典中找到Term ‘solr’,得到“solr” 对应文档的倒排表</li><li>合并链表，对两个文档链表做<strong>并集</strong>运算，合并过后结果就是即包含“lucene” 和 “sorl”</li></ol><h4><span id="not">NOT</span><a href="#not" class="header-anchor"></a></h4><p>指对多个集合求差集，比如，若要查找即包含字符串“lucene” 又要包含“solr”的文档，则查找步骤如下</p><ol><li>在词典中找到Term ‘lucene’,得到“lucene” 对应文档的倒排表</li><li>在词典中找到Term ‘solr’,得到“solr” 对应文档的倒排表</li><li>合并链表，对两个文档链表做<strong>差集</strong>，合并过后结果就是即包含“lucene” 和 “sorl”</li></ol><p><strong>小结</strong> ： 可以看到Lucene 提供的检索方式一般流程是先找字典，从字典里面找到倒排表，再根据倒排表求并集，交集，差集等操作得到最后结果</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#lucene-ji-chu-jiao-cheng&quot;&gt;Lucene 基础教程&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#luncene-ji-ben-jie-shao&quot;&gt;Lun
      
    
    </summary>
    
    
      <category term="Lucene" scheme="http://yoursite.com/tags/Lucene/"/>
    
      <category term="Elasticsearch" scheme="http://yoursite.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo 服务注册与发现</title>
    <link href="http://yoursite.com/2019/07/20/dubbo-registry/"/>
    <id>http://yoursite.com/2019/07/20/dubbo-registry/</id>
    <published>2019-07-20T09:16:45.000Z</published>
    <updated>2019-07-20T09:23:02.945Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#dubbo-fu-wu-zhu-ce-yu-fa-xian">Dubbo 服务注册与发现</a><ul><li><a href="#zookeeper-zhu-ce-zhong-xin">Zookeeper注册中心</a><ul><li><a href="#zookeeper-ji-qun-pei-zhi">Zookeeper 集群配置</a></li><li><a href="#zookeeper-zhu-ce-liu-cheng">Zookeeper 注册流程</a></li><li><a href="#zookeeper-fu-wu-bao-lu">Zookeeper 服务暴露</a></li><li><a href="#zookeeper-fu-wu-yin-yong">Zookeeper 服务引用</a></li><li><a href="#fu-wu-hui-diao">服务回调</a></li></ul></li></ul></li></ul><!-- tocstop --></div><h2><span id="dubbo-fu-wu-zhu-ce-yu-fa-xian">Dubbo 服务注册与发现</span><a href="#dubbo-fu-wu-zhu-ce-yu-fa-xian" class="header-anchor"></a></h2><p>Dubbo 支持多注册中心，不仅支持多种形式的注册中心，而且支持同时向多个注册中心注册，目前Dubbo支持的注册中心有四个</p><ul><li><strong>Multicast注册中心</strong>。 该注册中心不需要启动任何中心节点，只要广播地址一样，就可以互相发现。组播受网络结构限制，只适合小规模应用或者开发阶段使用，组播地址段为224.0.0.0~239.255.255.255</li><li><strong>ZooKeeper注册中心</strong>， 借助ZooKeeper 服务为注册中心</li><li><strong>Redis注册中心</strong>，为基于Redis实现的注册中心，使用Redis的Key/Map结构存储服务的URL地址以及过期时间，同时使用Redis的Publish/Subscriber事件通知数据变更</li><li><strong>Simple注册中心</strong>，它本身就是一个普通的Dubbo服务，可以减少第三方依赖，使用整体通信方式一致</li></ul><h3><span id="zookeeper-zhu-ce-zhong-xin">Zookeeper注册中心</span><a href="#zookeeper-zhu-ce-zhong-xin" class="header-anchor"></a></h3><p>我们在服务提供者（provider）和服务消费者（consumer）配置文件中使用<em>dubbo:service</em> 标签</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">address</span>=<span class="string">"zookeeper://127.0.0.1:2181"</span>/&gt;</span></span><br><span class="line"><span class="comment">&lt;!--或者--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">protocol</span>=<span class="string">"zookeeper"</span> <span class="attr">address</span>=<span class="string">"zookeeper://127.0.0.1:2181"</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>Dubbo 目前支持zkclient 和curator这两种ZooKeeper客户端实现，默认采用的是zkclient , 如果需要使用curator,则需要指定client=”curator”</p><h4><span id="zookeeper-ji-qun-pei-zhi">Zookeeper 集群配置</span><a href="#zookeeper-ji-qun-pei-zhi" class="header-anchor"></a></h4><p>单机配置如上一节所述，通常情况下我们会采用集群方式</p><ul><li><p>多节点单注册中心</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">address</span>=<span class="string">"zookeeper://127.0.0.1:2181?backup=127.0.0.2:2181,127.0.0.3:2181"</span>/&gt;</span></span><br><span class="line"><span class="comment">&lt;!--或者--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">protocol</span>=<span class="string">"zookeeper"</span> <span class="attr">address</span>=<span class="string">"127.0.0.1:2181,127.0.0.2:2181,127.0.0.3:2181"</span>/&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>多个注册中心</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">id</span>=<span class="string">"chengduRegistry"</span> <span class="attr">protocol</span>=<span class="string">"zookeeper"</span> <span class="attr">address</span>=<span class="string">"127.0.0.1:2181"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">id</span>=<span class="string">"shanghaiRegistry"</span> <span class="attr">protocol</span>=<span class="string">"zookeeper"</span> <span class="attr">address</span>=<span class="string">"127.0.0.2:2181"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span> <span class="attr">ref</span>=<span class="string">"demoService"</span> <span class="attr">registry</span>=<span class="string">"chengduRegistry,shanghaiRegistry"</span>/&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h4><span id="zookeeper-zhu-ce-liu-cheng">Zookeeper 注册流程</span><a href="#zookeeper-zhu-ce-liu-cheng" class="header-anchor"></a></h4><p>Dubbo 使用zookeeper 作为注册中心流程<br><img src="/2019/07/20/dubbo-registry/1563609275709.png" alt="Alt text"></p><ul><li>服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址</li><li>服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址</li><li>监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。</li></ul><p>支持以下功能：</p><ul><li>当提供者出现断电等异常停机时，注册中心能自动删除提供者信息</li><li>当注册中心重启时，能自动恢复注册数据，以及订阅请求</li><li>当会话过期时，能自动恢复注册数据，以及订阅请求</li><li>当设置 &lt;dubbo:registry check=”false” /&gt; 时，记录失败注册和订阅请求，后台定时重试</li><li>可通过 &lt;dubbo:registry username=”admin” password=”1234” /&gt; 设置 zookeeper 登录信息</li><li>可通过 &lt;dubbo:registry group=”dubbo” /&gt; 设置 zookeeper 的根节点，不设置将使用无根树</li><li>支持 * 号通配符 &lt;dubbo:reference group=”*” version=”*” /&gt;，可订阅服务的所有分组和所有版本的提供者</li></ul><h4><span id="zookeeper-fu-wu-bao-lu">Zookeeper 服务暴露</span><a href="#zookeeper-fu-wu-bao-lu" class="header-anchor"></a></h4><p>在服务通过注册中心注册后，需要使用&lt;dubbo:service/&gt;标签进行服务暴露</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--与本地Bean相同，声明Bean服务--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"demoService"</span> <span class="attr">class</span>=<span class="string">"com.lcc.dubbo.provider.DemoServiceImpl"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--申明需要暴露的服务接口--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span> <span class="attr">ref</span>=<span class="string">"demoService"</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>同时Dubbo还提供服务辅助性功能，比如初始化缓存，等待相关资源就位，控制并发量</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--延迟服务5秒暴露服务--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">delay</span>=<span class="string">"-1"</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span> <span class="attr">ref</span>=<span class="string">"demoService"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--设置为-1，表示延迟到Spring初始化完成过后再暴露服务--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">delay</span>=<span class="string">"5000"</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span> <span class="attr">ref</span>=<span class="string">"demoService"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--并发限制，限制接口中的每个方法并发执行个数不超过10--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">executes</span>=<span class="string">"10"</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span> <span class="attr">ref</span>=<span class="string">"demoService"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--限定某一个方法不超过10--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span> <span class="attr">ref</span>=<span class="string">"demoService"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dubbo:method</span> <span class="attr">name</span>=<span class="string">"sayHello"</span> <span class="attr">executes</span>=<span class="string">"10"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dubbo:service</span>&gt;</span></span><br></pre></td></tr></table></figure><h4><span id="zookeeper-fu-wu-yin-yong">Zookeeper 服务引用</span><a href="#zookeeper-fu-wu-yin-yong" class="header-anchor"></a></h4><p>在服务提供了暴露的，服务消费者就可以使用以下方式引用服务</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">id</span>=<span class="string">"demoService"</span> <span class="attr">check</span>=<span class="string">"true"</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span>/&gt;</span></span><br></pre></td></tr></table></figure><p>默认情况下Dubbo 采用的是同步调用方式，若想使用异步调用方式配置如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:dubbo</span>=<span class="string">"http://dubbo.apache.org/schema/dubbo"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span> <span class="attr">xmlns:context</span>=<span class="string">"http://www.springframework.org/schema/context"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">       http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:property-placeholder</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:application</span> <span class="attr">name</span>=<span class="string">"demo-consumer"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">address</span>=<span class="string">"zookeeper://127.0.0.1:2181"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--用dubbo协议在20880上面暴露端口--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:protocol</span> <span class="attr">name</span>=<span class="string">"dubbo"</span> <span class="attr">port</span>=<span class="string">"20880"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">id</span>=<span class="string">"demoService"</span> <span class="attr">check</span>=<span class="string">"true"</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dubbo:method</span> <span class="attr">name</span>=<span class="string">"sayHello"</span> <span class="attr">async</span>=<span class="string">"true"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dubbo:reference</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure><p>远程调用代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.dubbo.comsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.lcc.dubbo.provider.DemoService;</span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.rpc.RpcContext;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Future;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerApplicationWithAsync</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        ClassPathXmlApplicationContext context = <span class="keyword">new</span> ClassPathXmlApplicationContext(<span class="string">"dubbo-demo-consumer.xml"</span>);</span><br><span class="line">        DemoService demoService = (DemoService) context.getBean(<span class="string">"demoService"</span>);</span><br><span class="line">        demoService.sayHello(<span class="string">"world"</span>);</span><br><span class="line">        Future&lt;String&gt; future = RpcContext.getContext().getFuture();</span><br><span class="line">        String result = future.get();</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Dubbo 中的异步调用是基于NIO的非阻塞机制实现的，客户端不需要启动多线程即可完成并调用远端服务，相对于多线程开销较小，一些记录日志信息的服务可以直接使用异步调用执行</p><p>异步调用和同步调用的过程如图<br><img src="/2019/07/20/dubbo-registry/1563611454851.png" alt="Alt text"></p><h4><span id="fu-wu-hui-diao">服务回调</span><a href="#fu-wu-hui-diao" class="header-anchor"></a></h4><p>在远程调用事件过程中，如果出现了异常或者需要回调，则可以使用Dubbo 的事件通知机制，主要有以下三种</p><ul><li>oninvoke(原参数1，原参数2…..) : 为在发起远程调用之前触发的事件</li><li>onreturn(返回值，原参数1，原参数2….) ： 为远程调用之后的回调事件</li><li>onthrow(Throwable ex, 原参数1， 原参数2….): 为在远程调用出现异常时触发的事件，可以在该事件中实现服务的降级，返回一个默认值.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">INotify</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">onReturn</span><span class="params">(String resultStr, String inputStr)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">onThrow</span><span class="params">(Throwable throwable,String inputStr)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NotifyImpl</span> <span class="keyword">implements</span> <span class="title">INotify</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onReturn</span><span class="params">(String resultStr, String inputStr)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Get response."</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onThrow</span><span class="params">(Throwable throwable, String inputStr)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Get error"</span>);</span><br><span class="line">        throwable.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在消费者方配置指定事件通知接口</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"notify"</span> <span class="attr">class</span>=<span class="string">"com.lcc.dubbo.notify.NotifyImpl"</span>&gt;</span><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--收到reponse调用notify.onReturn 方法， 发生异常调用notify.onThrow 方法--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dubbo:reference</span> <span class="attr">id</span>=<span class="string">"demoService"</span> <span class="attr">check</span>=<span class="string">"true"</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dubbo:method</span> <span class="attr">name</span>=<span class="string">"sayHello"</span> <span class="attr">onreturn</span>=<span class="string">"notify.onReturn"</span></span></span><br><span class="line"><span class="tag">                      <span class="attr">onthrow</span>=<span class="string">"notify.onThrow"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dubbo:reference</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#dubbo-fu-wu-zhu-ce-yu-fa-xian&quot;&gt;Dubbo 服务注册与发现&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#zookeeper-zhu-ce-zhon
      
    
    </summary>
    
    
      <category term="Dubbo" scheme="http://yoursite.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo 配置管理</title>
    <link href="http://yoursite.com/2019/07/20/dubbo-configurations/"/>
    <id>http://yoursite.com/2019/07/20/dubbo-configurations/</id>
    <published>2019-07-20T03:43:10.000Z</published>
    <updated>2019-07-20T06:59:24.451Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#xml-pei-zhi">XML 配置</a></li><li><a href="#bu-tong-li-du-pei-zhi-fu-gai-guan-xi">不同粒度配置覆盖关系</a></li><li><a href="#shu-xing-pei-zhi">属性配置</a><ul><li><a href="#you-xian-ji-fu-gai">优先级覆盖</a></li></ul></li><li><a href="#api-pei-zhi">API 配置</a></li><li><a href="#zhu-jie-pei-zhi">注解配置</a><ul><li><a href="#pei-zhi-gong-gong-mo-kuai">配置公共模块</a></li><li><a href="#zhi-ding-dubbo-de-sao-miao-lu-jing">指定Dubbo 的扫描路径</a></li></ul></li><li><a href="#xiao-jie">小结</a></li></ul><!-- tocstop --></div><p>Dubbo 的配置主要分为三大类： <strong>服务发现</strong>，<strong>服务治理</strong>，<strong>性能调优</strong><br>这三类配置不是独立存在的，而是贯穿在所有配置项中，三类的配置主要作用如下</p><ul><li><strong>服务发现类</strong> ： 表示该配置项用于服务的注册与发现，目的是让消费者找到提供者</li><li><strong>服务治理类</strong> ： 表示该配置项用于治理服务间的关系，或为开发测试提供便利条件</li><li><strong>性能调优类</strong> ：表示该配置项用于性能调优</li></ul><h3><span id="xml-pei-zhi">XML 配置</span><a href="#xml-pei-zhi" class="header-anchor"></a></h3><p>我们可以采用XML的方式对Dubbo进行配置，因为Dubbo是使用Spring 的Schema进行扩展标签并且解析的，配置方式与Spring XML 方式雷同<br>例如在HelloWorld中配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:dubbo</span>=<span class="string">"http://dubbo.apache.org/schema/dubbo"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns</span>=<span class="string">"http://www.springframework.org/schema/beans"</span> <span class="attr">xmlns:context</span>=<span class="string">"http://www.springframework.org/schema/context"</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">       http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:property-placeholder</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--服务名称--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:application</span> <span class="attr">name</span>=<span class="string">"demo-provider"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--注册中心采用zookeeper,申明注册中心的地址和端口--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:registry</span> <span class="attr">address</span>=<span class="string">"zookeeper://127.0.0.1:2181"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--用dubbo协议在20880上面暴露端口--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:protocol</span> <span class="attr">name</span>=<span class="string">"dubbo"</span> <span class="attr">port</span>=<span class="string">"20880"</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--与本地Bean相同，声明Bean服务--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"demoService"</span> <span class="attr">class</span>=<span class="string">"com.lcc.dubbo.provider.DemoServiceImpl"</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--申明需要暴露的服务接口--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dubbo:service</span> <span class="attr">interface</span>=<span class="string">"com.lcc.dubbo.provider.DemoService"</span> <span class="attr">ref</span>=<span class="string">"demoService"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure><p>XML 配置标签关系如下图<br><img src="/2019/07/20/dubbo-configurations/1563588020357.png" alt="Alt text"><br>每个标签的用途和解释如下</p><table><thead><tr><th align="left">标签</th><th align="left">用途</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left">&lt;dubbo:service&gt;</td><td align="left">服务配置</td><td align="left">用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心</td></tr><tr><td align="left">&lt;dubbo:reference&gt;</td><td align="left">引用配置</td><td align="left">用于创建一个远程服务代理，一个引用可以指向多个注册中心</td></tr><tr><td align="left">&lt;dubbo:protocol&gt;</td><td align="left">协议配置</td><td align="left">用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受</td></tr><tr><td align="left">&lt;dubbo:application&gt;</td><td align="left">应用配置</td><td align="left">用于配置当前应用信息，不管该应用是提供者还是消费者</td></tr><tr><td align="left">&lt;dubbo:module&gt;</td><td align="left">模块配置</td><td align="left">用于配置当前模块信息，可选</td></tr><tr><td align="left">&lt;dubbo:registry&gt;</td><td align="left">注册中心配置</td><td align="left">用于配置连接注册中心相关信息</td></tr><tr><td align="left">&lt;dubbo:monitor&gt;</td><td align="left">监控中心配置</td><td align="left">用于配置连接监控中心相关信息，可选</td></tr><tr><td align="left">&lt;dubbo:provider&gt;</td><td align="left">提供方配置</td><td align="left">当 ProtocolConfig 和 ServiceConfig 某属性没有配置时，采用此缺省值，可选</td></tr><tr><td align="left">&lt;dubbo:consumer&gt;</td><td align="left">消费方配置</td><td align="left">当 ReferenceConfig 某属性没有配置时，采用此缺省值，可选</td></tr><tr><td align="left">&lt;dubbo:method&gt;</td><td align="left">方法配置</td><td align="left">用于 ServiceConfig 和 ReferenceConfig 指定方法级的配置信息</td></tr><tr><td align="left">&lt;dubbo:argument&gt;</td><td align="left">参数配置</td><td align="left">用于指定方法参数配置</td></tr></tbody></table><h3><span id="bu-tong-li-du-pei-zhi-fu-gai-guan-xi">不同粒度配置覆盖关系</span><a href="#bu-tong-li-du-pei-zhi-fu-gai-guan-xi" class="header-anchor"></a></h3><ul><li>方法级别优先，接口级别次之，全局配置再次之</li><li>如果级别一样，则消费方优先，提供方次之</li></ul><p><img src="/2019/07/20/dubbo-configurations/1563589453929.png" alt="Alt text"></p><blockquote><p>例如常用的超时设置建议服务方设置，因为服务方更加清楚一个方法需要执行多久，如果一个消费者同时引用了多个服务，就不需要关心每个服务的超时设置。</p></blockquote><h3><span id="shu-xing-pei-zhi">属性配置</span><a href="#shu-xing-pei-zhi" class="header-anchor"></a></h3><p>Dubbo 还支持使用properties文件进行配置，Dubbo 启动的时候会自动加载classpath 根目录下的dubbo.properties文件，也可以通过JVM 启动参数-Ddubbo.properties.file=mydubbo.properties来指定配置文件位置</p><figure class="highlight profile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dubbo.application.name=dubbo-server</span><br><span class="line">dubbo.application.owner=test</span><br><span class="line">dubbo.registry.address=zookeeper://<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">2181</span></span><br></pre></td></tr></table></figure><p>属性的配置规则遵守以下约定</p><ul><li>将XML 配置标签名加属性名，用点分隔，将多个属性拆分成多行</li><li>如果XMLy有多行同名标签配置，可以使用id号码区分，如果没有id号码，则将对所有同名的标签生效</li></ul><h4><span id="you-xian-ji-fu-gai">优先级覆盖</span><a href="#you-xian-ji-fu-gai" class="header-anchor"></a></h4><ul><li>JVM 启动-D参数优先，这样可以使用户在部署和启动的时候进行参数重写，比如在启动时候需要改变协议的端口</li><li>XML 次之，如果在XML中有配置，则dubbo.properties中的相应配置项无效</li><li>Properties最后，相当于默认值，只有XML没有被配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置</li></ul><h3><span id="api-pei-zhi">API 配置</span><a href="#api-pei-zhi" class="header-anchor"></a></h3><p>Dubbo 提供采用API方式进行配置，该方法一般用于Test,Mock， 在正式生产环境下推荐采用XML配置和属性配置方式<br>例如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.dubbo.provider;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.config.ApplicationConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.config.ProtocolConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.config.RegistryConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.config.ServiceConfig;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.ClassPathXmlApplicationContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProviderApplicationWithAPIConfig</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//当前应用的配置</span></span><br><span class="line">        ApplicationConfig applicationConfig = <span class="keyword">new</span> ApplicationConfig();</span><br><span class="line">        applicationConfig.setName(<span class="string">"dubbo-server"</span>);</span><br><span class="line">        <span class="comment">//连接注册中心配置</span></span><br><span class="line">        RegistryConfig registryConfig = <span class="keyword">new</span> RegistryConfig();</span><br><span class="line">        registryConfig.setAddress(<span class="string">"zookeeper://127.0.0.1:2181"</span>);</span><br><span class="line">        registryConfig.setUsername(<span class="string">"test"</span>);</span><br><span class="line">        registryConfig.setPassword(<span class="string">"123456"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//服务提供者协议的配置</span></span><br><span class="line">        ProtocolConfig protocolConfig = <span class="keyword">new</span> ProtocolConfig();</span><br><span class="line">        protocolConfig.setName(<span class="string">"dubbo"</span>);</span><br><span class="line">        protocolConfig.setPort(<span class="number">20880</span>);</span><br><span class="line">        protocolConfig.setThreads(<span class="number">200</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//下面的服务提供者暴露服务配置</span></span><br><span class="line">        DemoService demoService = <span class="keyword">new</span> DemoServiceImpl(); <span class="comment">//服务实现</span></span><br><span class="line"></span><br><span class="line">        ServiceConfig&lt;DemoService&gt; service = <span class="keyword">new</span> ServiceConfig&lt;DemoService&gt;();</span><br><span class="line">        service.setApplication(applicationConfig);</span><br><span class="line">        service.setRegistry(registryConfig);</span><br><span class="line">        service.setProtocol(protocolConfig);</span><br><span class="line">        service.setInterface(DemoService.class);</span><br><span class="line">        service.setRef(demoService);</span><br><span class="line">        <span class="comment">//service.setVersion("1.0.0");</span></span><br><span class="line">        <span class="comment">// 暴露接口</span></span><br><span class="line">        service.export();</span><br><span class="line">        System.out.println(<span class="string">"Dubbo service started."</span>);</span><br><span class="line">        <span class="comment">//挂起服务一直运行</span></span><br><span class="line">        <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>).await();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="zhu-jie-pei-zhi">注解配置</span><a href="#zhu-jie-pei-zhi" class="header-anchor"></a></h3><p>Dubbo 还支持通过注解的方式进行配置，该方式是在2.5.7版本之后新增的功能，可以节省大量的XML配置和属性配置，配置方式很像SpringBoot</p><h4><span id="pei-zhi-gong-gong-mo-kuai">配置公共模块</span><a href="#pei-zhi-gong-gong-mo-kuai" class="header-anchor"></a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.dubbo.annotation;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.config.ApplicationConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.config.RegistryConfig;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DubboConfiguration</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ApplicationConfig <span class="title">applicationConfig</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ApplicationConfig applicationConfig = <span class="keyword">new</span> ApplicationConfig();</span><br><span class="line">        applicationConfig.setName(<span class="string">"dubbo-server"</span>);</span><br><span class="line">        <span class="keyword">return</span> applicationConfig;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RegistryConfig <span class="title">registryConfig</span><span class="params">()</span></span>&#123;</span><br><span class="line">        RegistryConfig registryConfig = <span class="keyword">new</span> RegistryConfig();</span><br><span class="line">        registryConfig.setAddress(<span class="string">"zookeeper://127.0.0.1:2181"</span>);</span><br><span class="line">        <span class="keyword">return</span> registryConfig;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="zhi-ding-dubbo-de-sao-miao-lu-jing">指定Dubbo 的扫描路径</span><a href="#zhi-ding-dubbo-de-sao-miao-lu-jing" class="header-anchor"></a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.dubbo.annotation;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.dubbo.config.spring.context.annotation.DubboComponentScan;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@DubboComponentScan</span>(basePackages = <span class="string">"com.lcc.dubbo.annotation"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProviderApplicationWithAnnotation</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        SpringApplication.run(ProviderApplicationWithAnnotation.class, args);</span><br><span class="line">        System.out.println(<span class="string">"Dubbo service started."</span>);</span><br><span class="line">        Thread.sleep(<span class="number">100000</span>);</span><br><span class="line">        <span class="comment">//挂起服务一直运行</span></span><br><span class="line">        <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>).await();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="xiao-jie">小结</span><a href="#xiao-jie" class="header-anchor"></a></h3><p>总体来说，Dubbo 提供了多种方式进行配置，可以自行选择，采用注解方式这样可以很好的跟SpringBoot结合，SpringBoot 可以为客户端提供Restful形式的接口，而各内部服务之间使用Dubbo这样的RPC, 通信效率也得到了保证</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#xml-pei-zhi&quot;&gt;XML 配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#bu-tong-li-du-pei-zhi-fu-gai-guan-xi&quot;&gt;不同粒度配置覆
      
    
    </summary>
    
    
      <category term="Dubbo" scheme="http://yoursite.com/tags/Dubbo/"/>
    
  </entry>
  
  <entry>
    <title>HEXO 使用本地图片</title>
    <link href="http://yoursite.com/2019/07/10/hexo-using-local-image/"/>
    <id>http://yoursite.com/2019/07/10/hexo-using-local-image/</id>
    <published>2019-07-10T03:15:56.000Z</published>
    <updated>2019-07-20T07:06:56.673Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#hexo-shi-yong-ben-di-tu-pian">HEXO 使用本地图片</a><ul><li><a href="#hexo-asset-image-cha-jian-shi-yong">hexo-asset-image 插件使用</a><ul><li><a href="#an-zhuang-hexo-asset-image-cha-jian">安装hexo-asset-image 插件</a></li><li><a href="#pei-zhi-config-wen-jian">配置_config文件</a></li><li><a href="#chuang-jian-xin-de-wen-zhang">创建新的文章</a></li><li><a href="#zai-md-wen-jian-zhong-shi-yong-tu-pian">在md文件中使用图片</a></li></ul></li></ul></li></ul><!-- tocstop --></div><h2><span id="hexo-shi-yong-ben-di-tu-pian">HEXO 使用本地图片</span><a href="#hexo-shi-yong-ben-di-tu-pian" class="header-anchor"></a></h2><p>刚开始使用HEXO的时候，为了简单使用，将图片直接存放到图床上面，之前使用的是 <a href="https://sm.ms/" target="_blank" rel="noopener">https://sm.ms/</a>图床工具，<br>但是后来考虑到如果图床保留的图片都失效了，这会导致图片全部不能正常显示，所以就考虑转换到使用本地图片，这样不会导致图片失效<br>这里使用<strong>hexo-asset-image</strong> 插件</p><h3><span id="hexo-asset-image-cha-jian-shi-yong">hexo-asset-image 插件使用</span><a href="#hexo-asset-image-cha-jian-shi-yong" class="header-anchor"></a></h3><p>hexo-asset-image 是一个开源插件， github 地址可以访问<a href="https://github.com/xcodebuild/hexo-asset-image，" target="_blank" rel="noopener">https://github.com/xcodebuild/hexo-asset-image，</a> 使用起来非常方便</p><h4><span id="an-zhuang-hexo-asset-image-cha-jian">安装hexo-asset-image 插件</span><a href="#an-zhuang-hexo-asset-image-cha-jian" class="header-anchor"></a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-asset-image --save</span><br><span class="line">#或者</span><br><span class="line">npm install https:<span class="comment">//github.com/CodeFalling/hexo-asset-image --save</span></span><br></pre></td></tr></table></figure><h4><span id="pei-zhi-config-wen-jian">配置_config文件</span><a href="#pei-zhi-config-wen-jian" class="header-anchor"></a></h4><p>将_config文件的<em>post_asset_folder</em> 设置为true</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">post_asset_folder:<span class="keyword">true</span></span><br></pre></td></tr></table></figure><h4><span id="chuang-jian-xin-de-wen-zhang">创建新的文章</span><a href="#chuang-jian-xin-de-wen-zhang" class="header-anchor"></a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> hexo-using-local-image</span><br></pre></td></tr></table></figure><p>执行以上命令会创建一个hexo-using-local-image.md文件和hexo-using-local-image文件夹， hexo-using-local-image是用于存放图片<br>目录结构如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">source</span><br><span class="line">|---_posts</span><br><span class="line">    |--- hexo-using-local-image.md</span><br><span class="line">    |--- hexo-using-local-image</span><br></pre></td></tr></table></figure><h4><span id="zai-md-wen-jian-zhong-shi-yong-tu-pian">在md文件中使用图片</span><a href="#zai-md-wen-jian-zhong-shi-yong-tu-pian" class="header-anchor"></a></h4><p>按照markdown 格式使用图片</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![本地图片](hexo-using-local-image/hexo-banner.jpg)</span><br></pre></td></tr></table></figure><p><img src="/2019/07/10/hexo-using-local-image/hexo-banner.jpg" alt="本地图片"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#hexo-shi-yong-ben-di-tu-pian&quot;&gt;HEXO 使用本地图片&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#hexo-asset-image-cha-jia
      
    
    </summary>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习（三）Spark-SQL详解</title>
    <link href="http://yoursite.com/2019/06/30/spark-sql-programming/"/>
    <id>http://yoursite.com/2019/06/30/spark-sql-programming/</id>
    <published>2019-06-30T10:18:16.000Z</published>
    <updated>2019-07-05T10:13:47.486Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#spark-xue-xi-san-spark-sql-xiang-jie">Spark学习（三）Spark-SQL详解</a><ul><li><a href="#spark-sql-jian-jie">Spark SQL 简介</a><ul><li><a href="#spark-sql-jia-gou">Spark SQL 架构</a></li></ul></li><li><a href="#spark-sql-ji-ben-shi-yong">Spark SQL 基本使用</a><ul><li><a href="#sparksession-zhu-ru-kou">SparkSession主入口</a></li><li><a href="#chuang-jian-dataframes">创建DataFrames</a></li><li><a href="#dataframe-ji-ben-cao-zuo">DataFrame 基本操作</a></li><li><a href="#zhi-xing-dong-tai-bian-cheng-cha-xun-sql">执行动态编程查询SQL</a></li><li><a href="#quan-ju-lin-shi-shi-tu">全局临时视图</a></li><li><a href="#chuang-jian-shu-ju-ji">创建数据集</a></li><li><a href="#jiang-rdd-zhuan-huan-cheng-dataset">将RDD转换成Dataset</a><ul><li><a href="#shi-yong-fan-she-tui-duan-mo-shi">使用反射推断模式</a></li><li><a href="#yi-bian-cheng-fang-shi-zhi-ding-mo-shi">以编程方式指定模式</a></li></ul></li></ul></li><li><a href="#datasource-shu-ju-yuan">DataSource数据源</a></li></ul></li></ul><!-- tocstop --></div><h1><span id="spark-xue-xi-san-spark-sql-xiang-jie">Spark学习（三）Spark-SQL详解</span><a href="#spark-xue-xi-san-spark-sql-xiang-jie" class="header-anchor"></a></h1><p>@(BigData)[Spark, 大数据]</p><h2><span id="spark-sql-jian-jie">Spark SQL 简介</span><a href="#spark-sql-jian-jie" class="header-anchor"></a></h2><p>Spark SQL是一个用于结构化数据处理的Spark模块。与基本的Spark RDD API不同，Spark SQL提供的接口为Spark提供了关于数据结构和正在执行的计算的更多信息。</p><p>本文所有源代码可以访问<a href="https://github.com/ChangCheng-Lei/Java-Spark-Tutorial" target="_blank" rel="noopener">GIT HUB</a>获取</p><ol><li><strong>Datasets</strong>是分布式的数据集合，Dataset 支持Scala 和 JAVA的访问</li><li><strong>DataFrame</strong> 是组织成命名列的数据集</li></ol><h3><span id="spark-sql-jia-gou">Spark SQL 架构</span><a href="#spark-sql-jia-gou" class="header-anchor"></a></h3><p><img src="https://i.loli.net/2019/07/05/5d1f20e27348d22212.png" alt="1561425410767.png"></p><h2><span id="spark-sql-ji-ben-shi-yong">Spark SQL 基本使用</span><a href="#spark-sql-ji-ben-shi-yong" class="header-anchor"></a></h2><h3><span id="sparksession-zhu-ru-kou">SparkSession主入口</span><a href="#sparksession-zhu-ru-kou" class="header-anchor"></a></h3><p>Spark SQL 程序的主入口是SparkSession, 所以其余操作是基于SparkSession之上的，创建SparkSession代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SparkSession sparkSession = SparkSession.builder()</span><br><span class="line">                .appName(<span class="string">"Java Spark SQL basic example"</span>)</span><br><span class="line">                .master(<span class="string">"local"</span>)</span><br><span class="line">                .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>)</span><br><span class="line">                .getOrCreate();</span><br></pre></td></tr></table></figure><h3><span id="chuang-jian-dataframes">创建DataFrames</span><a href="#chuang-jian-dataframes" class="header-anchor"></a></h3><p>通过<em>SparkSession</em>, 程序可以通过已经存在的RDD, Hive table, Spark data sources 来创建DataFrame。<br>一下程序就是通过Json文件创建Dataset</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"></span><br><span class="line">Dataset&lt;Row&gt; df = spark.read().json(<span class="string">"examples/src/main/resources/people.json"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Displays the content of the DataFrame to stdout</span></span><br><span class="line">df.show();</span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// | age|   name|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// |null|Michael|</span></span><br><span class="line"><span class="comment">// |  30|   Andy|</span></span><br><span class="line"><span class="comment">// |  19| Justin|</span></span><br><span class="line"><span class="comment">// +----+-</span></span><br></pre></td></tr></table></figure><h3><span id="dataframe-ji-ben-cao-zuo">DataFrame 基本操作</span><a href="#dataframe-ji-ben-cao-zuo" class="header-anchor"></a></h3><p>DataFrame 基本操作类似于关系型数据库SQL操作,所有的操作可以查看<a href="http://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Dataset.html" target="_blank" rel="noopener">DataSet JAVA API</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// col("...") is preferable to df.col("...")</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.spark.sql.functions.col;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Print the schema in a tree format</span></span><br><span class="line">df.printSchema();</span><br><span class="line"><span class="comment">// root</span></span><br><span class="line"><span class="comment">// |-- age: long (nullable = true)</span></span><br><span class="line"><span class="comment">// |-- name: string (nullable = true)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Select only the "name" column</span></span><br><span class="line">df.select(<span class="string">"name"</span>).show();</span><br><span class="line"><span class="comment">// +-------+</span></span><br><span class="line"><span class="comment">// |   name|</span></span><br><span class="line"><span class="comment">// +-------+</span></span><br><span class="line"><span class="comment">// |Michael|</span></span><br><span class="line"><span class="comment">// |   Andy|</span></span><br><span class="line"><span class="comment">// | Justin|</span></span><br><span class="line"><span class="comment">// +-------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Select everybody, but increment the age by 1</span></span><br><span class="line">df.select(col(<span class="string">"name"</span>), col(<span class="string">"age"</span>).plus(<span class="number">1</span>)).show();</span><br><span class="line"><span class="comment">// +-------+---------+</span></span><br><span class="line"><span class="comment">// |   name|(age + 1)|</span></span><br><span class="line"><span class="comment">// +-------+---------+</span></span><br><span class="line"><span class="comment">// |Michael|     null|</span></span><br><span class="line"><span class="comment">// |   Andy|       31|</span></span><br><span class="line"><span class="comment">// | Justin|       20|</span></span><br><span class="line"><span class="comment">// +-------+---------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Select people older than 21</span></span><br><span class="line">df.filter(col(<span class="string">"age"</span>).gt(<span class="number">21</span>)).show();</span><br><span class="line"><span class="comment">// +---+----+</span></span><br><span class="line"><span class="comment">// |age|name|</span></span><br><span class="line"><span class="comment">// +---+----+</span></span><br><span class="line"><span class="comment">// | 30|Andy|</span></span><br><span class="line"><span class="comment">// +---+----+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Count people by age</span></span><br><span class="line">df.groupBy(<span class="string">"age"</span>).count().show();</span><br><span class="line"><span class="comment">// +----+-----+</span></span><br><span class="line"><span class="comment">// | age|count|</span></span><br><span class="line"><span class="comment">// +----+-----+</span></span><br><span class="line"><span class="comment">// |  19|    1|</span></span><br><span class="line"><span class="comment">// |null|    1|</span></span><br><span class="line"><span class="comment">// |  30|    1|</span></span><br><span class="line"><span class="comment">// +----+-----+</span></span><br></pre></td></tr></table></figure><h3><span id="zhi-xing-dong-tai-bian-cheng-cha-xun-sql">执行动态编程查询SQL</span><a href="#zhi-xing-dong-tai-bian-cheng-cha-xun-sql" class="header-anchor"></a></h3><p><em>sql</em>方法基于SparkSession之上，可以定置化查询语句，其返回结果是<strong>Dataset<row></row></strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Register the DataFrame as a SQL temporary view</span></span><br><span class="line">df.createOrReplaceTempView(<span class="string">"people"</span>);</span><br><span class="line"></span><br><span class="line">Dataset&lt;Row&gt; sqlDF = spark.sql(<span class="string">"SELECT * FROM people"</span>);</span><br><span class="line">sqlDF.show();</span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// | age|   name|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// |null|Michael|</span></span><br><span class="line"><span class="comment">// |  30|   Andy|</span></span><br><span class="line"><span class="comment">// |  19| Justin|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br></pre></td></tr></table></figure><h3><span id="quan-ju-lin-shi-shi-tu">全局临时视图</span><a href="#quan-ju-lin-shi-shi-tu" class="header-anchor"></a></h3><p>Spark 提供视图功能，分为<strong>临时视图</strong>和<strong>全局临时视图</strong>，<em>临时视图</em>是随着创建Session的终止而消亡，如果需要创建一个临时视图在所有session当中共享，直到Spark服务终止才会消亡，则可以创建一个<em>全局临时视图</em>，<em>全局临时视图</em>会将数据保存到<em>global_temp</em>数据库中，使用时候必须显示的指定数据库，例如<br>SELECT  * FROM global_temp.view1<br>示例代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Register the DataFrame as a global temporary view</span></span><br><span class="line">df.createGlobalTempView(<span class="string">"people"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Global temporary view is tied to a system preserved database `global_temp`</span></span><br><span class="line">spark.sql(<span class="string">"SELECT * FROM global_temp.people"</span>).show();</span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// | age|   name|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// |null|Michael|</span></span><br><span class="line"><span class="comment">// |  30|   Andy|</span></span><br><span class="line"><span class="comment">// |  19| Justin|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Global temporary view is cross-session</span></span><br><span class="line">spark.newSession().sql(<span class="string">"SELECT * FROM global_temp.people"</span>).show();</span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// | age|   name|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// |null|Michael|</span></span><br><span class="line"><span class="comment">// |  30|   Andy|</span></span><br><span class="line"><span class="comment">// |  19| Justin|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br></pre></td></tr></table></figure><h3><span id="chuang-jian-shu-ju-ji">创建数据集</span><a href="#chuang-jian-shu-ju-ji" class="header-anchor"></a></h3><p>数据集与RDDs类似，它们不是使用Java序列化或Kryo，而是使用专门的编码器序列化对象，以便通过网络进行处理或传输。虽然编码器和标准序列化都负责将对象转换为字节，但编码器是动态生成的代码，使用的格式允许Spark执行许多操作，比如过滤、排序和散列，而无需将字节反序列化回对象。</p><p>示例代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Encoder;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Encoders;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String name;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.age = age;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create an instance of a Bean class</span></span><br><span class="line">Person person = <span class="keyword">new</span> Person();</span><br><span class="line">person.setName(<span class="string">"Andy"</span>);</span><br><span class="line">person.setAge(<span class="number">32</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Encoders are created for Java beans</span></span><br><span class="line">Encoder&lt;Person&gt; personEncoder = Encoders.bean(Person.class);</span><br><span class="line">Dataset&lt;Person&gt; javaBeanDS = spark.createDataset(</span><br><span class="line">  Collections.singletonList(person),</span><br><span class="line">  personEncoder</span><br><span class="line">);</span><br><span class="line">javaBeanDS.show();</span><br><span class="line"><span class="comment">// +---+----+</span></span><br><span class="line"><span class="comment">// |age|name|</span></span><br><span class="line"><span class="comment">// +---+----+</span></span><br><span class="line"><span class="comment">// | 32|Andy|</span></span><br><span class="line"><span class="comment">// +---+----+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Encoders for most common types are provided in class Encoders</span></span><br><span class="line">Encoder&lt;Integer&gt; integerEncoder = Encoders.INT();</span><br><span class="line">Dataset&lt;Integer&gt; primitiveDS = spark.createDataset(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), integerEncoder);</span><br><span class="line">Dataset&lt;Integer&gt; transformedDS = primitiveDS.map(</span><br><span class="line">    (MapFunction&lt;Integer, Integer&gt;) value -&gt; value + <span class="number">1</span>,</span><br><span class="line">    integerEncoder);</span><br><span class="line">transformedDS.collect(); <span class="comment">// Returns [2, 3, 4]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// DataFrames can be converted to a Dataset by providing a class. Mapping based on name</span></span><br><span class="line">String path = <span class="string">"examples/src/main/resources/people.json"</span>;</span><br><span class="line">Dataset&lt;Person&gt; peopleDS = spark.read().json(path).as(personEncoder);</span><br><span class="line">peopleDS.show();</span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// | age|   name|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br><span class="line"><span class="comment">// |null|Michael|</span></span><br><span class="line"><span class="comment">// |  30|   Andy|</span></span><br><span class="line"><span class="comment">// |  19| Justin|</span></span><br><span class="line"><span class="comment">// +----+-------+</span></span><br></pre></td></tr></table></figure><h3><span id="jiang-rdd-zhuan-huan-cheng-dataset">将RDD转换成Dataset</span><a href="#jiang-rdd-zhuan-huan-cheng-dataset" class="header-anchor"></a></h3><p>Spark 支持两种方式将RDD转换成Dataset.</p><ol><li>第一种方法使用反射来推断包含特定对象类型的RDD的模式。这种基于反射的方法可以生成更简洁的代码，并且当您在编写Spark应用程序时已经知道模式时，这种方法可以很好地工作。</li><li>创建数据集的第二种方法是通过编程接口，该接口允许您构造模式，然后将其应用于现有的RDD。虽然这个方法更详细，但它允许您在列及其类型直到运行时才知道时构造数据集。</li></ol><h4><span id="shi-yong-fan-she-tui-duan-mo-shi">使用反射推断模式</span><a href="#shi-yong-fan-she-tui-duan-mo-shi" class="header-anchor"></a></h4><p>示例代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Encoder;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Encoders;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create an RDD of Person objects from a text file</span></span><br><span class="line">JavaRDD&lt;Person&gt; peopleRDD = spark.read()</span><br><span class="line">  .textFile(<span class="string">"examples/src/main/resources/people.txt"</span>)</span><br><span class="line">  .javaRDD()</span><br><span class="line">  .map(line -&gt; &#123;</span><br><span class="line">    String[] parts = line.split(<span class="string">","</span>);</span><br><span class="line">    Person person = <span class="keyword">new</span> Person();</span><br><span class="line">    person.setName(parts[<span class="number">0</span>]);</span><br><span class="line">    person.setAge(Integer.parseInt(parts[<span class="number">1</span>].trim()));</span><br><span class="line">    <span class="keyword">return</span> person;</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Apply a schema to an RDD of JavaBeans to get a DataFrame</span></span><br><span class="line">Dataset&lt;Row&gt; peopleDF = spark.createDataFrame(peopleRDD, Person.class);</span><br><span class="line"><span class="comment">// Register the DataFrame as a temporary view</span></span><br><span class="line">peopleDF.createOrReplaceTempView(<span class="string">"people"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL statements can be run by using the sql methods provided by spark</span></span><br><span class="line">Dataset&lt;Row&gt; teenagersDF = spark.sql(<span class="string">"SELECT name FROM people WHERE age BETWEEN 13 AND 19"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// The columns of a row in the result can be accessed by field index</span></span><br><span class="line">Encoder&lt;String&gt; stringEncoder = Encoders.STRING();</span><br><span class="line">Dataset&lt;String&gt; teenagerNamesByIndexDF = teenagersDF.map(</span><br><span class="line">    (MapFunction&lt;Row, String&gt;) row -&gt; <span class="string">"Name: "</span> + row.getString(<span class="number">0</span>),</span><br><span class="line">    stringEncoder);</span><br><span class="line">teenagerNamesByIndexDF.show();</span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"><span class="comment">// |       value|</span></span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"><span class="comment">// |Name: Justin|</span></span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// or by field name</span></span><br><span class="line">Dataset&lt;String&gt; teenagerNamesByFieldDF = teenagersDF.map(</span><br><span class="line">    (MapFunction&lt;Row, String&gt;) row -&gt; <span class="string">"Name: "</span> + row.&lt;String&gt;getAs(<span class="string">"name"</span>),</span><br><span class="line">    stringEncoder);</span><br><span class="line">teenagerNamesByFieldDF.show();</span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"><span class="comment">// |       value|</span></span><br><span class="line"><span class="comment">// +------------+</span></span><br><span class="line"><span class="comment">// |Name: Justin|</span></span><br><span class="line"><span class="comment">// +------------+</span></span><br></pre></td></tr></table></figure><h4><span id="yi-bian-cheng-fang-shi-zhi-ding-mo-shi">以编程方式指定模式</span><a href="#yi-bian-cheng-fang-shi-zhi-ding-mo-shi" class="header-anchor"></a></h4><p>示例代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">mport java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.DataTypes;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructField;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.StructType;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create an RDD</span></span><br><span class="line">JavaRDD&lt;String&gt; peopleRDD = spark.sparkContext()</span><br><span class="line">  .textFile(<span class="string">"examples/src/main/resources/people.txt"</span>, <span class="number">1</span>)</span><br><span class="line">  .toJavaRDD();</span><br><span class="line"></span><br><span class="line"><span class="comment">// The schema is encoded in a string</span></span><br><span class="line">String schemaString = <span class="string">"name age"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Generate the schema based on the string of schema</span></span><br><span class="line">List&lt;StructField&gt; fields = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (String fieldName : schemaString.split(<span class="string">" "</span>)) &#123;</span><br><span class="line">StructField field = DataTypes.createStructField(fieldName, DataTypes.StringType, <span class="keyword">true</span>);</span><br><span class="line">  fields.add(field);</span><br><span class="line">&#125;</span><br><span class="line">StructType schema = DataTypes.createStructType(fields);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Convert records of the RDD (people) to Rows</span></span><br><span class="line">JavaRDD&lt;Row&gt; rowRDD = peopleRDD.map((Function&lt;String, Row&gt;) record -&gt; &#123;</span><br><span class="line">  String[] attributes = record.split(<span class="string">","</span>);</span><br><span class="line">  <span class="keyword">return</span> RowFactory.create(attributes[<span class="number">0</span>], attributes[<span class="number">1</span>].trim());</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Apply the schema to the RDD</span></span><br><span class="line">Dataset&lt;Row&gt; peopleDataFrame = spark.createDataFrame(rowRDD, schema);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Creates a temporary view using the DataFrame</span></span><br><span class="line">peopleDataFrame.createOrReplaceTempView(<span class="string">"people"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQL can be run over a temporary view created using DataFrames</span></span><br><span class="line">Dataset&lt;Row&gt; results = spark.sql(<span class="string">"SELECT name FROM people"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations</span></span><br><span class="line"><span class="comment">// The columns of a row in the result can be accessed by field index or by field name</span></span><br><span class="line">Dataset&lt;String&gt; namesDS = results.map(</span><br><span class="line">    (MapFunction&lt;Row, String&gt;) row -&gt; <span class="string">"Name: "</span> + row.getString(<span class="number">0</span>),</span><br><span class="line">    Encoders.STRING());</span><br><span class="line">namesDS.show();</span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |        value|</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |Name: Michael|</span></span><br><span class="line"><span class="comment">// |   Name: Andy|</span></span><br><span class="line"><span class="comment">// | Name: Justin|</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br></pre></td></tr></table></figure><h2><span id="datasource-shu-ju-yuan">DataSource数据源</span><a href="#datasource-shu-ju-yuan" class="header-anchor"></a></h2><p>Spark SQL支持通过DataFrame interfac对各种数据源进行操作，现在支持<strong>ORC文件</strong>，<strong>JSON文件</strong>，<strong>HIVE table</strong>,<strong>JDBC</strong>,<strong>Avro文件</strong><br>详细文档参考<a href="http://spark.apache.org/docs/latest/sql-data-sources.html" target="_blank" rel="noopener">官方文档</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#spark-xue-xi-san-spark-sql-xiang-jie&quot;&gt;Spark学习（三）Spark-SQL详解&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#spark-
      
    
    </summary>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习（二）RDD详解</title>
    <link href="http://yoursite.com/2019/06/23/spark-rdd-programming/"/>
    <id>http://yoursite.com/2019/06/23/spark-rdd-programming/</id>
    <published>2019-06-23T08:18:16.000Z</published>
    <updated>2019-07-05T06:24:26.200Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#rdd-jian-jie">RDD 简介</a><ul><li><a href="#ji-ben-gai-nian">基本概念</a></li><li><a href="#chuang-jian-rdd">创建RDD</a><ul><li><a href="#parallelized-collections">Parallelized Collections</a></li><li><a href="#external-datasets-cong-wai-bu-wen-jian-du-qu">External Datasets 从外部文件读取</a></li></ul></li></ul></li><li><a href="#rdd-cao-zuo">RDD 操作</a><ul><li><a href="#transformation">Transformation</a><ul><li><a href="#flatmap-he-map">flatMap 和 Map</a></li><li><a href="#sample-cao-zuo">sample 操作</a></li><li><a href="#distinct-cao-zuo">distinct 操作</a></li><li><a href="#union-he-bing-cao-zuo">union 合并操作</a></li><li><a href="#intersection-jiao-ji">intersection 交集</a></li><li><a href="#substract-zi-ji">substract 子集</a></li><li><a href="#cartesian-di-qia-er-ji">cartesian 笛卡尔积</a></li></ul></li><li><a href="#actions">Actions</a><ul><li><a href="#collect-cao-zuo">collect 操作</a></li><li><a href="#count-he-countbyvalue">count 和 countByValue</a></li><li><a href="#take-cao-zuo">take 操作</a></li><li><a href="#saveastextfile-cao-zuo">saveAsTextFile 操作</a></li><li><a href="#reduce-cao-zuo">reduce 操作</a></li></ul></li></ul></li></ul><!-- tocstop --></div><h2><span id="rdd-jian-jie">RDD 简介</span><a href="#rdd-jian-jie" class="header-anchor"></a></h2><blockquote><p>Resilient Distributed Dataset 意思是弹性分布式数据集,是Spark 中最基本的数据抽象</p></blockquote><p>本文所有源代码可以访问<a href="https://github.com/ChangCheng-Lei/Java-Spark-Tutorial" target="_blank" rel="noopener">GIT HUB</a> 获取</p><h3><span id="ji-ben-gai-nian">基本概念</span><a href="#ji-ben-gai-nian" class="header-anchor"></a></h3><ul><li>dataset : dataset 是一系列数据的集合，它的展现形式可以是Strings,  integers 甚至是存放在关系型数据库中的数据 </li></ul><h3><span id="chuang-jian-rdd">创建RDD</span><a href="#chuang-jian-rdd" class="header-anchor"></a></h3><blockquote><p>创建RDD 有两种方式，<em>Parallelized Collections</em> 和 <em>External Datasets</em></p></blockquote><p>在JAVA maven 项目中， 添加依赖即可引用spark 相关类</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在maven 项目一般使用方式如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.spark;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloWordSpark</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String appName = "HellowWorld"; #项目名称</span><br><span class="line">        String master = "local"; # 运行模式</span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(appName).setMaster(master);</span><br><span class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="parallelized-collections">Parallelized Collections</span><a href="#parallelized-collections" class="header-anchor"></a></h4><p>将现有的数据直接转换成RDD , 但是一般使用场景不太会用到</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; data = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; distData = sc.parallelize(data);</span><br></pre></td></tr></table></figure><h4><span id="external-datasets-cong-wai-bu-wen-jian-du-qu">External Datasets 从外部文件读取</span><a href="#external-datasets-cong-wai-bu-wen-jian-du-qu" class="header-anchor"></a></h4><p>一般情况下需要分析的Spark文件都比较大，存放在HDFS或者HBASe 等外部文件，比较适用实际使用场景<br>使用方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; distFile = sc.textFile(<span class="string">"data.txt"</span>);</span><br></pre></td></tr></table></figure><h2><span id="rdd-cao-zuo">RDD 操作</span><a href="#rdd-cao-zuo" class="header-anchor"></a></h2><blockquote><p>RDD 主要包含transformaitons 和 actions 两个阶段的操作</p></blockquote><h3><span id="transformation">Transformation</span><a href="#transformation" class="header-anchor"></a></h3><blockquote><p>Transformation 主要目的是转换数据， 从已经存在的数据集上新创建一个</p></blockquote><p>transformations 是RDD上一系列操作，可以返回一个<strong>新的RDD</strong>，Spark 中所有的transformation都是采用的LAZY模式，他不会立马计算出结果，直到有操作需要计算新的RDD时才会进行计算，默认情况下，每一个transformed RDD 每次调用可能出现重复计算，可以通过<em>persist</em> RDD 到内存。</p><blockquote><p>注意 ： transformations 会返回一个新的Rdd</p></blockquote><p>最常见的transformation 操作时<strong>过滤filter</strong> 和 <strong>映射map</strong>操作<br>代码案例–统计文本中每个单词出现的次数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.spark;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hello world!</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordsCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String appName = <span class="string">"HellowWorld"</span>;</span><br><span class="line">        String master = <span class="string">"local"</span>;</span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(appName).setMaster(master);</span><br><span class="line">        JavaSparkContext sparkContext = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line">        JavaRDD&lt;String&gt; stringJavaRDD = sparkContext.textFile(<span class="string">"src/main/resources/input/word_count.text"</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; objectJavaRDD = stringJavaRDD.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterator&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(s.split(<span class="string">" "</span>)).iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Map&lt;String, Long&gt; stringLongMap = objectJavaRDD.countByValue();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, Long&gt; entry : stringLongMap.entrySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Key = "</span> + entry.getKey() + <span class="string">", Value = "</span> + entry.getValue());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="flatmap-he-map">flatMap 和 Map</span><a href="#flatmap-he-map" class="header-anchor"></a></h4><p><img src="https://i.loli.net/2019/07/05/5d1eeb31393e167850.png" alt="1560780323084.png"><br><strong>Map</strong>适用场景为<strong>1对1</strong>映射关系<br><img src="https://i.loli.net/2019/07/05/5d1eeb307fa8d34013.png" alt="1560780356961.png"><br><strong>FlatMap</strong>适用场景是<strong>1对多</strong>映射关系<br><img src="https://i.loli.net/2019/07/05/5d1eeb30ccd7c49936.png" alt="1560780392131.png"></p><h4><span id="sample-cao-zuo">sample 操作</span><a href="#sample-cao-zuo" class="header-anchor"></a></h4><p>sample 操作会返回一个随机的rdd， 常用语获取随机数据</p><h4><span id="distinct-cao-zuo">distinct 操作</span><a href="#distinct-cao-zuo" class="header-anchor"></a></h4><p>返回唯一的distinct操作</p><h4><span id="union-he-bing-cao-zuo">union 合并操作</span><a href="#union-he-bing-cao-zuo" class="header-anchor"></a></h4><p>union 操作实质是求并集合， union = A U B</p><h4><span id="intersection-jiao-ji">intersection 交集</span><a href="#intersection-jiao-ji" class="header-anchor"></a></h4><p>intersection operation 操作实质是求交集 intersection = A∩B</p><blockquote><p>注意 intersection 操作时非常消耗资源的，因为需要把所有的分区都遍历才能获取到交集<br>所获取到的交集结果会去重处理</p></blockquote><h4><span id="substract-zi-ji">substract 子集</span><a href="#substract-zi-ji" class="header-anchor"></a></h4><blockquote><p>注意 intersection 操作时非常消耗资源的，因为需要把所有的分区都遍历才能获取到子集</p></blockquote><h4><span id="cartesian-di-qia-er-ji">cartesian 笛卡尔积</span><a href="#cartesian-di-qia-er-ji" class="header-anchor"></a></h4><p>返回RDD A 和 RDD B 笛卡尔积</p><h3><span id="actions">Actions</span><a href="#actions" class="header-anchor"></a></h3><blockquote><p>actions是将最终值返回给驱动程序或将数据持久化到外部存储系统的操作</p></blockquote><h4><span id="collect-cao-zuo">collect 操作</span><a href="#collect-cao-zuo" class="header-anchor"></a></h4><h4><span id="count-he-countbyvalue">count 和 countByValue</span><a href="#count-he-countbyvalue" class="header-anchor"></a></h4><ul><li><strong>count</strong> 用于统计有多行数据在当前rdd当中，count 会返回有多少元素</li><li><strong>countByValue</strong> 会在当前RDD下，按照唯一值进行计数， 并返回一个map(这个很类似mysql的count函数)</li></ul><h4><span id="take-cao-zuo">take 操作</span><a href="#take-cao-zuo" class="header-anchor"></a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words = wordRdd.tabke(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><ul><li>take action 从当前RDD 当中获取N个元素</li><li>take action 常用语单元测试和debug</li></ul><h4><span id="saveastextfile-cao-zuo">saveAsTextFile 操作</span><a href="#saveastextfile-cao-zuo" class="header-anchor"></a></h4><p>saveAsTextFile操作主要是将数据存放到硬盘中，这个查询之前的即可</p><h4><span id="reduce-cao-zuo">reduce 操作</span><a href="#reduce-cao-zuo" class="header-anchor"></a></h4><p>reduce 操作与mapReduce 中思想一样</p><p><img src="https://i.loli.net/2019/07/05/5d1eeb311fd2313743.png" alt="1560780429240.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#rdd-jian-jie&quot;&gt;RDD 简介&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ji-ben-gai-nian&quot;&gt;基本概念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#
      
    
    </summary>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Spark学习（1）安装Spark</title>
    <link href="http://yoursite.com/2019/06/16/sparkInstall/"/>
    <id>http://yoursite.com/2019/06/16/sparkInstall/</id>
    <published>2019-06-16T08:18:16.000Z</published>
    <updated>2019-06-16T08:56:41.341Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#spark-jian-jie">Spark 简介</a></li><li><a href="#spark-an-zhuang">Spark 安装</a><ul><li><a href="#cai-yong-an-zhuang-bao-de-fang-shi-an-zhuang">采用安装包的方式安装</a><ul><li><a href="#linux-shang-an-zhuang-spark">LINUX 上安装Spark</a></li><li><a href="#windows-an-zhuang-spark">Windows 安装Spark</a></li><li><a href="#cai-yong-yuan-ma-fang-shi-an-zhuang">采用源码方式安装</a></li></ul></li></ul></li></ul><!-- tocstop --></div><h2><span id="spark-jian-jie">Spark 简介</span><a href="#spark-jian-jie" class="header-anchor"></a></h2><blockquote><p>Apache Spark™ is a unified analytics engine for large-scale data processing.<br>若需要查询更多信息，访问Spark <a href="https://spark.apache.org/" target="_blank" rel="noopener">官方网站</a><br>若需要查询Spark源码，访问Spark <a href="https://github.com/apache/spark" target="_blank" rel="noopener">Git Hub</a></p></blockquote><p>Spark 是一个快速且通用的集群计算平台</p><ul><li>Spark 是快速的 Spark 扩充了流行MapReduce 计算模型， 基于内存计算</li><li>Spark 通用的， 容纳了其它分布式系统拥有的功能，批处理，迭代式计算，交互式查询和流处理，降低集群维护成本</li><li>高度开放的，提供了Python, Java等高级API</li></ul><h2><span id="spark-an-zhuang">Spark 安装</span><a href="#spark-an-zhuang" class="header-anchor"></a></h2><p>Spark 安装方式提供两种安装模式，<strong>编译源码安装</strong> 和 <strong>安装包方式安装</strong>示例安装系统为windows，Linux , 参照对应操作系统安装即可</p><p>系统环境要求</p><ol><li><strong>安装JAVA JDK1.8</strong><br>为什么需要安装JAVA JDK1.8 ？</li></ol><ul><li>Spark 是采用Scala 语言编写，Scala语言是运行在JVM上的</li><li>Python API（PySpark） 与Spark进行交互, PySpark 是在<em>Spark‘s JAVA API</em>之上的封装,JAVA API 也是需要JDK</li><li>JAVA JDK 版本要求是1.8</li></ul><h3><span id="cai-yong-an-zhuang-bao-de-fang-shi-an-zhuang">采用安装包的方式安装</span><a href="#cai-yong-an-zhuang-bao-de-fang-shi-an-zhuang" class="header-anchor"></a></h3><ol><li>打开Spark <a href="https://spark.apache.org/" target="_blank" rel="noopener">官方网站</a>，点击DownLoad, 这里已经Spark 已经集成成功了hadoop组件，可以直接使用<br><img src="https://i.loli.net/2019/06/16/5d05fd9d8fa2f41078.png" alt="1.png"></li></ol><h4><span id="linux-shang-an-zhuang-spark">LINUX 上安装Spark</span><a href="#linux-shang-an-zhuang-spark" class="header-anchor"></a></h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@Amy ~]<span class="comment"># mkdir download</span></span><br><span class="line">[root@Amy ~]<span class="comment"># cd download/</span></span><br><span class="line"><span class="comment">#wget &lt;spark_url&gt; //使用wget 命令下载spark</span></span><br><span class="line">[root@Amy download]<span class="comment">#</span></span><br><span class="line">wget http://mirror.bit.edu.cn/apache/spark/spark-<span class="number">2.4</span>.<span class="number">3</span>/spark-<span class="number">2.4</span>.<span class="number">3</span>-bin-hadoop2.<span class="number">7</span>.tgz</span><br><span class="line">mkdir /opt/apache-spark <span class="comment"># spakr 解压目录</span></span><br><span class="line">[root@Amy download]<span class="comment"># tar xvzf spark-2.4.3-bin-hadoop2.7.tgz -C /opt/apache-spark/</span></span><br></pre></td></tr></table></figure><ol start="3"><li>配置环境变量<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@Amy download]<span class="comment"># cd /opt/apache-spark/spark-2.4.3-bin-hadoop2.7/</span></span><br><span class="line">[root@Amy spark-<span class="number">2.4</span>.<span class="number">3</span>-bin-hadoop2.<span class="number">7</span>]<span class="comment"># vim ~/.bashrc</span></span><br><span class="line"><span class="comment">#将Spark 环境配置加入</span></span><br><span class="line"><span class="comment">#export SPARK_HOME=/opt/apache-spark/spark-2.4.3-bin-hadoop2.7</span></span><br><span class="line"><span class="comment">#export PATH=$PATH:$SPARK_HOME/bin</span></span><br><span class="line"><span class="comment">#保存文件并退出</span></span><br><span class="line">[root@Amy spark-<span class="number">2.4</span>.<span class="number">3</span>-bin-hadoop2.<span class="number">7</span>]<span class="comment"># source ~/.bashrc # 使得环境变量生效</span></span><br><span class="line">[root@Amy spark-<span class="number">2.4</span>.<span class="number">3</span>-bin-hadoop2.<span class="number">7</span>]<span class="comment"># pyspark # 执行pySpark 命令</span></span><br></pre></td></tr></table></figure></li></ol><p>pySpark 命令正确执行结果如下<br><img src="https://i.loli.net/2019/06/16/5d05fd9d6762132822.png" alt="2.png"></p><h4><span id="windows-an-zhuang-spark">Windows 安装Spark</span><a href="#windows-an-zhuang-spark" class="header-anchor"></a></h4><ol><li><p>通过浏览下载刚刚选择的Spark 版本</p></li><li><p>将Spark解压到需要保存的文件目录<br>这里以D盘根目录为例<br><img src="https://i.loli.net/2019/06/16/5d05fd9db812640075.png" alt="3.png"></p><blockquote><p><strong>注意</strong> Spark 的安装与其它操作系统没有区别，但是由于Windows操作系统采用的是NTFS格式，hadoop 不能完全兼容所需，所以需要稍微进行处理</p></blockquote></li><li><p>下载<a href="https://github.com/jleetutorial/sparkTutorial/blob/winutils/winutils.exe" target="_blank" rel="noopener">工具</a><br>保存路径到<em>D:\hadoop\bin</em>（这里需要注意，后续配置环境变量需要）</p></li><li><p>配置环境变量</p></li></ol><ul><li>配置<em>HADOOP_HOME</em> 为 <em>D:\hadoop</em>（与上一步hadoop工具一致）</li><li>配置<em>SPARK_HOME *为</em>D:\spark-2.4.3-bin-hadoop2.7*（Spark 保存路径）</li><li>添加Hadoop 和Spark 到Path 中</li></ul><ol start="4"><li>校验安装是否成功</li></ol><ul><li>新创建一个文件目录<em>D:\tmp\hive</em>，使用工具修改文件夹格式<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\Administrator&gt;winutils chmod <span class="number">777</span> D:\tmp\hive</span><br><span class="line">C:\Users\Administrator&gt;pyspark</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://i.loli.net/2019/06/16/5d05fd9d7e00675647.png" alt="4.png"></p><h4><span id="cai-yong-yuan-ma-fang-shi-an-zhuang">采用源码方式安装</span><a href="#cai-yong-yuan-ma-fang-shi-an-zhuang" class="header-anchor"></a></h4><p>详细源码安装<a href="http://spark.apache.org/docs/latest/building-spark.html" target="_blank" rel="noopener">官方文档</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#spark-jian-jie&quot;&gt;Spark 简介&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#spark-an-zhuang&quot;&gt;Spark 安装&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a
      
    
    </summary>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>制作HEXO Docker 镜像</title>
    <link href="http://yoursite.com/2019/06/08/build-hexo-with-docker/"/>
    <id>http://yoursite.com/2019/06/08/build-hexo-with-docker/</id>
    <published>2019-06-08T03:15:56.000Z</published>
    <updated>2019-06-08T07:31:03.975Z</updated>
    
    <content type="html"><![CDATA[<div class="toc"><!-- toc --><ul><li><a href="#zhi-zuo-hexo-docker-jing-xiang">制作HEXO Docker镜像</a><ul><li><a href="#qi-dong-docker-rong-qi">启动docker 容器</a></li><li><a href="#pei-zhi-ubuntu-apt-get-shu-ju-yuan">配置ubuntu apt-get数据源</a></li><li><a href="#ubuntu-an-zhuang-git">ubuntu安装git</a></li><li><a href="#an-zhuang-node-js">安装node js</a><ul><li><a href="#huo-qu-node-js-ban-ben">获取node js 版本</a></li></ul></li><li><a href="#an-zhuang-hexo">安装hexo</a></li><li><a href="#jiang-rong-qi-da-cheng-jing-xiang">将容器打成镜像</a></li><li><a href="#pei-zhi-tu-pian-cha-jian">配置图片插件</a></li><li><a href="#can-kao-wen-dang">参考文档</a></li></ul></li></ul><!-- tocstop --></div><h2><span id="zhi-zuo-hexo-docker-jing-xiang">制作HEXO Docker镜像</span><a href="#zhi-zuo-hexo-docker-jing-xiang" class="header-anchor"></a></h2><p>Hexo是一个基于node.js的静态博客生成系统，它使用markdown语法来写作，同时支持丰富的自定义标签系统。但是对于后端开发者来讲， 本身对于Nodejs 不太熟悉，如果更换电脑又得捣腾一遍环境，所以笔者直接将hexo环境打成docker镜像，以便日后更好的使用</p><p>镜像路径 : <a href="https://hub.docker.com/r/changchenglei/hexo" target="_blank" rel="noopener">https://hub.docker.com/r/changchenglei/hexo</a><br>拉取镜像指令:  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull changchenglei/hexo</span><br></pre></td></tr></table></figure><p>本文采用ubuntu做为操作系统，进行容器化搭建.</p><h3><span id="qi-dong-docker-rong-qi">启动docker 容器</span><a href="#qi-dong-docker-rong-qi" class="header-anchor"></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull ubuntu <span class="comment"># 拉取最新的ubuntu镜像</span></span><br><span class="line">docker run --name hexo_blog -d -i -t ubuntu <span class="comment">#启动容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it hexo_blog <span class="string">"/bin/bash"</span> <span class="comment">#进入容器进行安装</span></span><br></pre></td></tr></table></figure><h3><span id="pei-zhi-ubuntu-apt-get-shu-ju-yuan">配置ubuntu apt-get数据源</span><a href="#pei-zhi-ubuntu-apt-get-shu-ju-yuan" class="header-anchor"></a></h3><blockquote><p>当网络缓慢可以设置，若网络良好可以直接忽略<br>配置apt-get 数据源主要是为了加快下载速度，若网络速度已经很快可以不用修改</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">docker run --name hexo_blog -d -i -t ubuntu</span><br><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources_init.list</span><br><span class="line">apt-get update</span><br><span class="line">apt-get upgrade</span><br><span class="line">apt-get install sudo</span><br><span class="line">apt-get install vim</span><br><span class="line">sudo vi /etc/apt/sources.list <span class="comment">#配置阿里数据源</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -f install</span><br></pre></td></tr></table></figure><p>配置apt-get 阿里数据源， 不要删除原有的，将阿里数据源添加到最前面</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">deb http://mirrors.aliyun.com/ubuntu/ xenial main</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ xenial main</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ xenial universe</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ xenial universe</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ xenial-updates universe</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates universe</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ xenial-security main</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ xenial-security universe</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security universe</span><br></pre></td></tr></table></figure><h3><span id="ubuntu-an-zhuang-git">ubuntu安装git</span><a href="#ubuntu-an-zhuang-git" class="header-anchor"></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get install git <span class="comment">#这里会自动安装包</span></span><br><span class="line">git --version</span><br></pre></td></tr></table></figure><h3><span id="an-zhuang-node-js">安装node js</span><a href="#an-zhuang-node-js" class="header-anchor"></a></h3><h4><span id="huo-qu-node-js-ban-ben">获取node js 版本</span><a href="#huo-qu-node-js-ban-ben" class="header-anchor"></a></h4><ol><li>打开<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">官网下载</a></li><li>找到需要下载的版本， 右键制下载链接， 这里以node-v12.3.1 为例<br><img src="https://i.loli.net/2019/06/08/5cfb56abc14f540413.png" alt="nodeJs.png"><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install wget</span><br><span class="line">wget https://nodejs.org/dist/v12.3.1/node-v12.3.1-linux-x64.tar.xz  </span><br><span class="line">tar -xJf node-v12.3.1-linux-x64.tar.xz -C /opt</span><br><span class="line">sudo ln -s /opt/node-v12.3.1-linux-x64/bin/node /usr/<span class="built_in">local</span>/bin/node <span class="comment">#建立软连接</span></span><br><span class="line">sudo ln -s /opt/node-v12.3.1-linux-x64/bin/npm /usr/<span class="built_in">local</span>/bin/npm <span class="comment">#建立软连接</span></span><br><span class="line">npm -v</span><br><span class="line">node -v</span><br><span class="line">sudo npm config <span class="built_in">set</span> registry https://registry.npm.taobao.org <span class="comment">#设置阿里npm数据源</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc <span class="comment">#设置数据源立马生效</span></span><br></pre></td></tr></table></figure></li></ol><h3><span id="an-zhuang-hexo">安装hexo</span><a href="#an-zhuang-hexo" class="header-anchor"></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br><span class="line">sudo ln -s /opt/node-v12.3.1-linux-x64/bin/hexo /usr/<span class="built_in">local</span>/bin/hexo <span class="comment">#建立hexo软连接</span></span><br></pre></td></tr></table></figure><p>默认hexo 工作间是在/home/hexo 目录下，有需求可以自行更改</p><h3><span id="jiang-rong-qi-da-cheng-jing-xiang">将容器打成镜像</span><a href="#jiang-rong-qi-da-cheng-jing-xiang" class="header-anchor"></a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker commit -m <span class="string">"Add original docker hexo enviroment, inclue node js(v12.3.1) , git(2.17.1), hexo "</span> -a <span class="string">"LeiChangCheng"</span> 273901f62fb9 docker.io/changchenglei/hexo</span><br></pre></td></tr></table></figure><h3><span id="pei-zhi-tu-pian-cha-jian">配置图片插件</span><a href="#pei-zhi-tu-pian-cha-jian" class="header-anchor"></a></h3><ol><li>把主页配置文件_config.yml 里的post_asset_folder:这个选项设置为true</li><li>在根目录下输入npm install –save hexo-asset-image，这是下载安装一个可以上传本地图片的插件<br>再运行hexo new “xxxx”来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹<br>最后在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片即可<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">![<span class="string">Alt text</span>](<span class="link">https://i.loli.net/2019/06/08/5cfb56abc14f540413.png</span>) // 互联网查找图片</span><br><span class="line">![<span class="string">Alt text</span>](<span class="link">./nodejs.png</span>) //本地查找图片</span><br></pre></td></tr></table></figure></li></ol><h3><span id="can-kao-wen-dang">参考文档</span><a href="#can-kao-wen-dang" class="header-anchor"></a></h3><p>[1] <a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">hexo配置</a><br>[2] <a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">hexo建站</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div class=&quot;toc&quot;&gt;

&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#zhi-zuo-hexo-docker-jing-xiang&quot;&gt;制作HEXO Docker镜像&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#qi-dong-docker-ron
      
    
    </summary>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
  </entry>
  
</feed>
