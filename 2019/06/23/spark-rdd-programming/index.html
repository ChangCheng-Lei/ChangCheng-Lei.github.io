<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>Spark学习（二）RDD详解 | ChangCheng Blog</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="HEXO,SpringCLoud,MySQL,JAVA,Docker,微服务"><meta name="description" content="日常学习与兴趣交流的个人博客"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="http://yoursite.com/2019/06/23/spark-rdd-programming/index.html"><link rel="icon" type="image/png" href="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1559928506945&di=406e9b9d2e125205da3c71fdfe56aedc&imgtype=0&src=http%3A%2F%2Fp5.so.qhimgs1.com%2Ft01031f510e7406ba8b.jpg" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="ChangCheng"><link rel="stylesheet" href="/scss/views/page/post.css"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(https://blog.static.minfive.com/other/loader.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="ChangCheng" alt="ChangCheng"><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1559928575075&di=8c27770cd8f303fae3c33eb59b8c5519&imgtype=0&src=http%3A%2F%2Fimg.ph.126.net%2Fju7M-CM1VEWcZGXPJlgmDA%3D%3D%2F3275242829007105662.png" alt="ChangCheng"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="https://i.loli.net/2019/06/16/5d05fd9da592065728.jpg" alt="Spark学习（二）RDD详解"></div><header class="post__info"><h1 class="post__title">Spark学习（二）RDD详解</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://github.com/ChangCheng-Lei">雷昌诚</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2019-06-23</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/Spark/">Spark</a></li><li class="mark__item"><a href="/tags/大数据/">大数据</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#rdd-jian-jie">RDD 简介</a><ul><li><a href="#ji-ben-gai-nian">基本概念</a></li><li><a href="#chuang-jian-rdd">创建RDD</a><ul><li><a href="#parallelized-collections">Parallelized Collections</a></li><li><a href="#external-datasets-cong-wai-bu-wen-jian-du-qu">External Datasets 从外部文件读取</a></li></ul></li></ul></li><li><a href="#rdd-cao-zuo">RDD 操作</a><ul><li><a href="#transformation">Transformation</a><ul><li><a href="#flatmap-he-map">flatMap 和 Map</a></li><li><a href="#sample-cao-zuo">sample 操作</a></li><li><a href="#distinct-cao-zuo">distinct 操作</a></li><li><a href="#union-he-bing-cao-zuo">union 合并操作</a></li><li><a href="#intersection-jiao-ji">intersection 交集</a></li><li><a href="#substract-zi-ji">substract 子集</a></li><li><a href="#cartesian-di-qia-er-ji">cartesian 笛卡尔积</a></li></ul></li><li><a href="#actions">Actions</a><ul><li><a href="#collect-cao-zuo">collect 操作</a></li><li><a href="#count-he-countbyvalue">count 和 countByValue</a></li><li><a href="#take-cao-zuo">take 操作</a></li><li><a href="#saveastextfile-cao-zuo">saveAsTextFile 操作</a></li><li><a href="#reduce-cao-zuo">reduce 操作</a></li></ul></li></ul></li></ul></div><h2><span id="rdd-jian-jie">RDD 简介</span><a href="#rdd-jian-jie" class="header-anchor"></a></h2><blockquote><p>Resilient Distributed Dataset 意思是弹性分布式数据集,是Spark 中最基本的数据抽象</p></blockquote><p>本文所有源代码可以访问<a href="https://github.com/ChangCheng-Lei/Java-Spark-Tutorial" target="_blank" rel="noopener">GIT HUB</a> 获取</p><h3><span id="ji-ben-gai-nian">基本概念</span><a href="#ji-ben-gai-nian" class="header-anchor"></a></h3><ul><li>dataset : dataset 是一系列数据的集合，它的展现形式可以是Strings, integers 甚至是存放在关系型数据库中的数据</li></ul><h3><span id="chuang-jian-rdd">创建RDD</span><a href="#chuang-jian-rdd" class="header-anchor"></a></h3><blockquote><p>创建RDD 有两种方式，<em>Parallelized Collections</em> 和 <em>External Datasets</em></p></blockquote><p>在JAVA maven 项目中， 添加依赖即可引用spark 相关类</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在maven 项目一般使用方式如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.spark;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloWordSpark</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String appName = "HellowWorld"; #项目名称</span><br><span class="line">        String master = "local"; # 运行模式</span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(appName).setMaster(master);</span><br><span class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="parallelized-collections">Parallelized Collections</span><a href="#parallelized-collections" class="header-anchor"></a></h4><p>将现有的数据直接转换成RDD , 但是一般使用场景不太会用到</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; data = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; distData = sc.parallelize(data);</span><br></pre></td></tr></table></figure><h4><span id="external-datasets-cong-wai-bu-wen-jian-du-qu">External Datasets 从外部文件读取</span><a href="#external-datasets-cong-wai-bu-wen-jian-du-qu" class="header-anchor"></a></h4><p>一般情况下需要分析的Spark文件都比较大，存放在HDFS或者HBASe 等外部文件，比较适用实际使用场景<br>使用方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; distFile = sc.textFile(<span class="string">"data.txt"</span>);</span><br></pre></td></tr></table></figure><h2><span id="rdd-cao-zuo">RDD 操作</span><a href="#rdd-cao-zuo" class="header-anchor"></a></h2><blockquote><p>RDD 主要包含transformaitons 和 actions 两个阶段的操作</p></blockquote><h3><span id="transformation">Transformation</span><a href="#transformation" class="header-anchor"></a></h3><blockquote><p>Transformation 主要目的是转换数据， 从已经存在的数据集上新创建一个</p></blockquote><p>transformations 是RDD上一系列操作，可以返回一个<strong>新的RDD</strong>， Spark 中所有的transformation都是采用的LAZY模式，他不会立马计算出结果，直到有操作需要计算新的RDD时才会进行计算，默认情况下，每一个transformed RDD 每次调用可能出现重复计算，可以通过<em>persist</em> RDD 到内存。</p><blockquote><p>注意 ： transformations 会返回一个新的Rdd</p></blockquote><p>最常见的transformation 操作时<strong>过滤filter</strong> 和 <strong>映射map</strong>操作<br>代码案例–统计文本中每个单词出现的次数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.lcc.spark;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hello world!</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordsCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String appName = <span class="string">"HellowWorld"</span>;</span><br><span class="line">        String master = <span class="string">"local"</span>;</span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(appName).setMaster(master);</span><br><span class="line">        JavaSparkContext sparkContext = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line">        JavaRDD&lt;String&gt; stringJavaRDD = sparkContext.textFile(<span class="string">"src/main/resources/input/word_count.text"</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; objectJavaRDD = stringJavaRDD.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterator&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(s.split(<span class="string">" "</span>)).iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Map&lt;String, Long&gt; stringLongMap = objectJavaRDD.countByValue();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, Long&gt; entry : stringLongMap.entrySet()) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Key = "</span> + entry.getKey() + <span class="string">", Value = "</span> + entry.getValue());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="flatmap-he-map">flatMap 和 Map</span><a href="#flatmap-he-map" class="header-anchor"></a></h4><p><img src="https://i.loli.net/2019/07/05/5d1eeb31393e167850.png" alt="1560780323084.png"><br><strong>Map</strong>适用场景为<strong>1对1</strong>映射关系<br><img src="https://i.loli.net/2019/07/05/5d1eeb307fa8d34013.png" alt="1560780356961.png"><br><strong>FlatMap</strong>适用场景是<strong>1对多</strong>映射关系<br><img src="https://i.loli.net/2019/07/05/5d1eeb30ccd7c49936.png" alt="1560780392131.png"></p><h4><span id="sample-cao-zuo">sample 操作</span><a href="#sample-cao-zuo" class="header-anchor"></a></h4><p>sample 操作会返回一个随机的rdd， 常用语获取随机数据</p><h4><span id="distinct-cao-zuo">distinct 操作</span><a href="#distinct-cao-zuo" class="header-anchor"></a></h4><p>返回唯一的distinct操作</p><h4><span id="union-he-bing-cao-zuo">union 合并操作</span><a href="#union-he-bing-cao-zuo" class="header-anchor"></a></h4><p>union 操作实质是求并集合， union = A U B</p><h4><span id="intersection-jiao-ji">intersection 交集</span><a href="#intersection-jiao-ji" class="header-anchor"></a></h4><p>intersection operation 操作实质是求交集 intersection = A∩B</p><blockquote><p>注意 intersection 操作时非常消耗资源的，因为需要把所有的分区都遍历才能获取到交集<br>所获取到的交集结果会去重处理</p></blockquote><h4><span id="substract-zi-ji">substract 子集</span><a href="#substract-zi-ji" class="header-anchor"></a></h4><blockquote><p>注意 intersection 操作时非常消耗资源的，因为需要把所有的分区都遍历才能获取到子集</p></blockquote><h4><span id="cartesian-di-qia-er-ji">cartesian 笛卡尔积</span><a href="#cartesian-di-qia-er-ji" class="header-anchor"></a></h4><p>返回RDD A 和 RDD B 笛卡尔积</p><h3><span id="actions">Actions</span><a href="#actions" class="header-anchor"></a></h3><blockquote><p>actions是将最终值返回给驱动程序或将数据持久化到外部存储系统的操作</p></blockquote><h4><span id="collect-cao-zuo">collect 操作</span><a href="#collect-cao-zuo" class="header-anchor"></a></h4><h4><span id="count-he-countbyvalue">count 和 countByValue</span><a href="#count-he-countbyvalue" class="header-anchor"></a></h4><ul><li><strong>count</strong> 用于统计有多行数据在当前rdd当中，count 会返回有多少元素</li><li><strong>countByValue</strong> 会在当前RDD下，按照唯一值进行计数， 并返回一个map(这个很类似mysql的count函数)</li></ul><h4><span id="take-cao-zuo">take 操作</span><a href="#take-cao-zuo" class="header-anchor"></a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words = wordRdd.tabke(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><ul><li>take action 从当前RDD 当中获取N个元素</li><li>take action 常用语单元测试和debug</li></ul><h4><span id="saveastextfile-cao-zuo">saveAsTextFile 操作</span><a href="#saveastextfile-cao-zuo" class="header-anchor"></a></h4><p>saveAsTextFile操作主要是将数据存放到硬盘中，这个查询之前的即可</p><h4><span id="reduce-cao-zuo">reduce 操作</span><a href="#reduce-cao-zuo" class="header-anchor"></a></h4><p>reduce 操作与mapReduce 中思想一样</p><p><img src="https://i.loli.net/2019/07/05/5d1eeb311fd2313743.png" alt="1560780429240.png"></p><div class="post-announce">感谢您的阅读，本文由 <a href="https://github.com/ChangCheng-Lei">雷昌诚</a> 原创提供。如若转载，请注明出处：雷昌诚（<a href="https://github.com/ChangCheng-Lei">https://github.com/ChangCheng-Lei</a>）</div><div class="post__prevs"><div class="post__prev"><a href="/2019/06/16/sparkInstall/" title="Spark学习（1）安装Spark"><i class="iconfont icon-prev"></i>Spark学习（1）安装Spark</a></div><div class="post__prev post__prev--right"><a href="/2019/06/30/spark-sql-programming/" title="Spark学习（三）Spark-SQL详解">Spark学习（三）Spark-SQL详解<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">日常学习与兴趣交流的个人博客</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2019/07/10/hexo-using-local-image/" title="HEXO 使用本地图片"><div class="item__cover"><img src="http://47.99.130.173:4000/2019/07/10/hexo-using-local-image/hexo-banner.jpg" alt="HEXO 使用本地图片"></div><div class="item__info"><h3 class="item__title">HEXO 使用本地图片</h3><span class="item__text">2019-07-10</span></div></a></li><li class="latest-post-item"><a href="/2019/06/30/spark-sql-programming/" title="Spark学习（三）Spark-SQL详解"><div class="item__cover"><img src="https://i.loli.net/2019/06/16/5d05fd9da592065728.jpg" alt="Spark学习（三）Spark-SQL详解"></div><div class="item__info"><h3 class="item__title">Spark学习（三）Spark-SQL详解</h3><span class="item__text">2019-06-30</span></div></a></li><li class="latest-post-item"><a href="/2019/06/23/spark-rdd-programming/" title="Spark学习（二）RDD详解"><div class="item__cover"><img src="https://i.loli.net/2019/06/16/5d05fd9da592065728.jpg" alt="Spark学习（二）RDD详解"></div><div class="item__info"><h3 class="item__title">Spark学习（二）RDD详解</h3><span class="item__text">2019-06-23</span></div></a></li><li class="latest-post-item"><a href="/2019/06/16/sparkInstall/" title="Spark学习（1）安装Spark"><div class="item__cover"><img src="https://i.loli.net/2019/06/16/5d05fd9da592065728.jpg" alt="Spark学习（1）安装Spark"></div><div class="item__info"><h3 class="item__title">Spark学习（1）安装Spark</h3><span class="item__text">2019-06-16</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/Spark/">Spark</a></li><li class="tag-item"><a class="tag-link" href="/tags/docker/">docker</a></li><li class="tag-item"><a class="tag-link" href="/tags/hexo/">hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/大数据/">大数据</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活及工作的一些心得总结，欢迎点击右下角订阅 rss。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>ChengDu, SiChuan Province, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>leichangchengvip@163.com</span></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>.</p><ul class="footer__social-network clearfix"></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></body></html>